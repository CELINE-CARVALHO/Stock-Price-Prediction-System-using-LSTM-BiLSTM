{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS-U_vxqmOUj",
        "outputId": "c6b5fef9-5df0-443d-8d2e-6e63fd3644a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=744a3c8732dd728e5eef6befea4e7f3cc110415f671af4d0ef920ba446b1da6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance scikit-learn tensorflow pandas numpy matplotlib gradio ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # FULLY DEBUGGED Stock Predictor - LSTM + Bidirectional LSTM Only\n",
        "# # Comprehensive error handling and logging built-in\n",
        "\n",
        "# import os, time, threading, traceback, warnings\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import yfinance as yf\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models, callbacks\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')  # Non-interactive backend\n",
        "# import matplotlib.pyplot as plt\n",
        "# import gradio as gr\n",
        "\n",
        "# # Suppress warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# # ---------------- CONFIG ----------------\n",
        "# TOP_10_STOCKS = [\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\"NFLX\",\"JPM\",\"AMD\"]\n",
        "# MODELS_DIR = \"/content/stock_models\"\n",
        "# os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# # OPTIMIZED FOR SPEED\n",
        "# SEQ_LEN = 20\n",
        "# POLL_INTERVAL = 10\n",
        "# EPOCHS = 3\n",
        "# BATCH_SIZE = 64\n",
        "\n",
        "# # Shared state\n",
        "# LIVE_STATE = {}\n",
        "# POLLERS = {}\n",
        "# TRAIN_LOGS = {}\n",
        "# TRAINING_FLAGS = {}\n",
        "\n",
        "# # ---------------- LOGGING UTILITY ----------------\n",
        "# class Logger:\n",
        "#     def __init__(self, symbol):\n",
        "#         self.symbol = symbol\n",
        "#         self.logs = []\n",
        "\n",
        "#     def log(self, msg, level=\"INFO\"):\n",
        "#         timestamp = time.strftime(\"%H:%M:%S\")\n",
        "#         emoji = {\"INFO\": \"â„¹ï¸\", \"SUCCESS\": \"âœ…\", \"ERROR\": \"âŒ\", \"WARNING\": \"âš ï¸\"}.get(level, \"ðŸ“\")\n",
        "#         line = f\"[{timestamp}] {emoji} {msg}\"\n",
        "#         self.logs.append(line)\n",
        "#         print(line)\n",
        "#         TRAIN_LOGS[self.symbol] = \"\\n\".join(self.logs)\n",
        "#         return line\n",
        "\n",
        "# # ---------------- DATA FUNCTIONS ----------------\n",
        "# def download_stock_data(symbol, period='1y', logger=None):\n",
        "#     \"\"\"Download stock data with error handling\"\"\"\n",
        "#     try:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Downloading {symbol} data ({period})...\")\n",
        "\n",
        "#         df = yf.download(symbol, period=period, interval='1d',\n",
        "#                         progress=False, auto_adjust=True, threads=False)\n",
        "\n",
        "#         if df.empty:\n",
        "#             raise ValueError(f\"No data returned for {symbol}\")\n",
        "\n",
        "#         # Handle multi-level columns\n",
        "#         if isinstance(df.columns, pd.MultiIndex):\n",
        "#             df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "#         # Keep only OHLCV\n",
        "#         required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "#         df = df[required_cols].copy()\n",
        "\n",
        "#         # Drop NaN\n",
        "#         df = df.dropna()\n",
        "\n",
        "#         if logger:\n",
        "#             logger.log(f\"Downloaded {len(df)} rows\", \"SUCCESS\")\n",
        "\n",
        "#         return df\n",
        "\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# def add_technical_indicators(df, logger=None):\n",
        "#     \"\"\"Add simple technical indicators without external libraries\"\"\"\n",
        "#     try:\n",
        "#         if logger:\n",
        "#             logger.log(\"Adding technical indicators...\")\n",
        "\n",
        "#         # Ensure Close is 1D\n",
        "#         close = df['Close'].values.flatten()\n",
        "\n",
        "#         # Simple Moving Average\n",
        "#         df['SMA_10'] = pd.Series(close).rolling(window=10).mean()\n",
        "\n",
        "#         # Exponential Moving Average\n",
        "#         df['EMA_10'] = pd.Series(close).ewm(span=10, adjust=False).mean()\n",
        "\n",
        "#         # RSI (Relative Strength Index) - manual calculation\n",
        "#         delta = pd.Series(close).diff()\n",
        "#         gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "#         loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "#         rs = gain / loss\n",
        "#         df['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "#         # Volume change\n",
        "#         df['Volume_Change'] = pd.Series(df['Volume'].values).pct_change()\n",
        "\n",
        "#         # Drop NaN from indicators\n",
        "#         df = df.dropna()\n",
        "\n",
        "#         if logger:\n",
        "#             logger.log(f\"Added indicators, {len(df)} rows remaining\", \"SUCCESS\")\n",
        "\n",
        "#         return df\n",
        "\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Indicator calculation failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# def prepare_sequences(df, seq_len=SEQ_LEN, logger=None):\n",
        "#     \"\"\"Prepare sequences for training\"\"\"\n",
        "#     try:\n",
        "#         if logger:\n",
        "#             logger.log(\"Preparing sequences...\")\n",
        "\n",
        "#         # Feature columns\n",
        "#         feature_cols = ['Close', 'SMA_10', 'EMA_10', 'RSI_14', 'Volume_Change']\n",
        "\n",
        "#         # Verify all columns exist\n",
        "#         missing = [col for col in feature_cols if col not in df.columns]\n",
        "#         if missing:\n",
        "#             raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "#         # Get values and scale\n",
        "#         arr = df[feature_cols].values.astype(np.float32)\n",
        "\n",
        "#         scaler = MinMaxScaler()\n",
        "#         scaled = scaler.fit_transform(arr)\n",
        "\n",
        "#         # Create sequences\n",
        "#         X, y = [], []\n",
        "#         for i in range(seq_len, len(scaled)):\n",
        "#             X.append(scaled[i-seq_len:i])\n",
        "#             y.append(scaled[i, 0])  # Predict Close price\n",
        "\n",
        "#         X = np.array(X, dtype=np.float32)\n",
        "#         y = np.array(y, dtype=np.float32)\n",
        "\n",
        "#         if logger:\n",
        "#             logger.log(f\"Created {len(X)} sequences\", \"SUCCESS\")\n",
        "\n",
        "#         return X, y, scaler, len(feature_cols)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Sequence preparation failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# # ---------------- MODEL ARCHITECTURES ----------------\n",
        "# def build_lstm_model(seq_len, n_features):\n",
        "#     \"\"\"Simple LSTM model\"\"\"\n",
        "#     model = models.Sequential([\n",
        "#         layers.Input(shape=(seq_len, n_features)),\n",
        "#         layers.LSTM(64, return_sequences=True),\n",
        "#         layers.Dropout(0.2),\n",
        "#         layers.LSTM(32),\n",
        "#         layers.Dense(16, activation='relu'),\n",
        "#         layers.Dense(1)\n",
        "#     ])\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#         loss='mse',\n",
        "#         metrics=['mae']\n",
        "#     )\n",
        "#     return model\n",
        "\n",
        "# def build_bidirectional_lstm_model(seq_len, n_features):\n",
        "#     \"\"\"Bidirectional LSTM model\"\"\"\n",
        "#     model = models.Sequential([\n",
        "#         layers.Input(shape=(seq_len, n_features)),\n",
        "#         layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
        "#         layers.Dropout(0.2),\n",
        "#         layers.Bidirectional(layers.LSTM(32)),\n",
        "#         layers.Dense(16, activation='relu'),\n",
        "#         layers.Dense(1)\n",
        "#     ])\n",
        "#     model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#         loss='mse',\n",
        "#         metrics=['mae']\n",
        "#     )\n",
        "#     return model\n",
        "\n",
        "# # ---------------- MODEL SAVE/LOAD ----------------\n",
        "# def save_model_safe(model, path, logger=None):\n",
        "#     \"\"\"Save model in TF SavedModel format\"\"\"\n",
        "#     try:\n",
        "#         save_path = path.replace('.h5', '_saved_model')\n",
        "#         model.save(save_path, save_format='tf')\n",
        "#         if logger:\n",
        "#             logger.log(f\"Model saved to {save_path}\", \"SUCCESS\")\n",
        "#         return save_path\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Save failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# def load_model_safe(path, logger=None):\n",
        "#     \"\"\"Load model from SavedModel format\"\"\"\n",
        "#     try:\n",
        "#         load_path = path.replace('.h5', '_saved_model')\n",
        "#         if not os.path.exists(load_path):\n",
        "#             raise FileNotFoundError(f\"Model not found at {load_path}\")\n",
        "\n",
        "#         model = tf.keras.models.load_model(load_path)\n",
        "#         if logger:\n",
        "#             logger.log(f\"Model loaded from {load_path}\", \"SUCCESS\")\n",
        "#         return model\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Load failed: {str(e)}\", \"ERROR\")\n",
        "#         return None\n",
        "\n",
        "# # ---------------- TRAINING THREAD ----------------\n",
        "# def train_models_thread(symbol):\n",
        "#     \"\"\"Background training with comprehensive error handling\"\"\"\n",
        "#     TRAINING_FLAGS[symbol] = True\n",
        "#     logger = Logger(symbol)\n",
        "\n",
        "#     try:\n",
        "#         logger.log(f\"ðŸš€ Starting training for {symbol}\")\n",
        "\n",
        "#         # Step 1: Download data\n",
        "#         df = download_stock_data(symbol, period='1y', logger=logger)\n",
        "\n",
        "#         # Step 2: Add indicators\n",
        "#         df = add_technical_indicators(df, logger=logger)\n",
        "\n",
        "#         # Step 3: Prepare sequences\n",
        "#         X, y, scaler, n_features = prepare_sequences(df, SEQ_LEN, logger=logger)\n",
        "\n",
        "#         # Check data size\n",
        "#         if len(X) < 100:\n",
        "#             raise ValueError(f\"Insufficient data: {len(X)} samples (need 100+)\")\n",
        "\n",
        "#         # Step 4: Train/test split\n",
        "#         split_idx = int(len(X) * 0.8)\n",
        "#         X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "#         y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "#         logger.log(f\"Training: {len(X_train)} samples, Testing: {len(X_test)} samples\")\n",
        "\n",
        "#         # Step 5: Train LSTM\n",
        "#         logger.log(\"ðŸ—ï¸ Building LSTM model...\")\n",
        "#         lstm_model = build_lstm_model(SEQ_LEN, n_features)\n",
        "\n",
        "#         logger.log(f\"ðŸŽ“ Training LSTM ({EPOCHS} epochs)...\")\n",
        "#         history_lstm = lstm_model.fit(\n",
        "#             X_train, y_train,\n",
        "#             validation_data=(X_test, y_test),\n",
        "#             epochs=EPOCHS,\n",
        "#             batch_size=BATCH_SIZE,\n",
        "#             verbose=0,\n",
        "#             callbacks=[\n",
        "#                 callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
        "#             ]\n",
        "#         )\n",
        "\n",
        "#         final_loss = history_lstm.history['val_loss'][-1]\n",
        "#         logger.log(f\"LSTM trained! Val Loss: {final_loss:.4f}\", \"SUCCESS\")\n",
        "\n",
        "#         # Save LSTM\n",
        "#         lstm_path = os.path.join(MODELS_DIR, f\"{symbol}_lstm.h5\")\n",
        "#         save_model_safe(lstm_model, lstm_path, logger)\n",
        "\n",
        "#         # Step 6: Train Bidirectional LSTM\n",
        "#         logger.log(\"ðŸ—ï¸ Building Bidirectional LSTM model...\")\n",
        "#         bilstm_model = build_bidirectional_lstm_model(SEQ_LEN, n_features)\n",
        "\n",
        "#         logger.log(f\"ðŸŽ“ Training Bidirectional LSTM ({EPOCHS} epochs)...\")\n",
        "#         history_bilstm = bilstm_model.fit(\n",
        "#             X_train, y_train,\n",
        "#             validation_data=(X_test, y_test),\n",
        "#             epochs=EPOCHS,\n",
        "#             batch_size=BATCH_SIZE,\n",
        "#             verbose=0,\n",
        "#             callbacks=[\n",
        "#                 callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
        "#             ]\n",
        "#         )\n",
        "\n",
        "#         final_loss = history_bilstm.history['val_loss'][-1]\n",
        "#         logger.log(f\"Bidirectional LSTM trained! Val Loss: {final_loss:.4f}\", \"SUCCESS\")\n",
        "\n",
        "#         # Save Bidirectional LSTM\n",
        "#         bilstm_path = os.path.join(MODELS_DIR, f\"{symbol}_bilstm.h5\")\n",
        "#         save_model_safe(bilstm_model, bilstm_path, logger)\n",
        "\n",
        "#         # Step 7: Save scaler\n",
        "#         scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.npz\")\n",
        "#         np.savez(scaler_path,\n",
        "#                  min=scaler.min_,\n",
        "#                  scale=scaler.scale_,\n",
        "#                  feature_names=np.array(['Close', 'SMA_10', 'EMA_10', 'RSI_14', 'Volume_Change']))\n",
        "#         logger.log(\"Scaler saved\", \"SUCCESS\")\n",
        "\n",
        "#         logger.log(\"ðŸŽ‰ Training completed successfully!\")\n",
        "#         logger.log(f\"â±ï¸ Models ready for {symbol}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         logger.log(f\"Training failed: {str(e)}\", \"ERROR\")\n",
        "#         logger.log(\"Traceback:\", \"ERROR\")\n",
        "#         for line in traceback.format_exc().split('\\n'):\n",
        "#             if line.strip():\n",
        "#                 logger.log(line, \"ERROR\")\n",
        "\n",
        "#     finally:\n",
        "#         TRAINING_FLAGS[symbol] = False\n",
        "\n",
        "# # ---------------- HELPER FUNCTIONS ----------------\n",
        "# def is_trained(symbol):\n",
        "#     \"\"\"Check if models exist\"\"\"\n",
        "#     lstm_path = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "#     bilstm_path = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "#     scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.npz\")\n",
        "\n",
        "#     return (os.path.exists(lstm_path) and\n",
        "#             os.path.exists(bilstm_path) and\n",
        "#             os.path.exists(scaler_path))\n",
        "\n",
        "# def load_models_and_scaler(symbol):\n",
        "#     \"\"\"Load both models and scaler\"\"\"\n",
        "#     logger = Logger(symbol)\n",
        "\n",
        "#     lstm_path = os.path.join(MODELS_DIR, f\"{symbol}_lstm.h5\")\n",
        "#     bilstm_path = os.path.join(MODELS_DIR, f\"{symbol}_bilstm.h5\")\n",
        "#     scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.npz\")\n",
        "\n",
        "#     lstm_model = load_model_safe(lstm_path, logger)\n",
        "#     bilstm_model = load_model_safe(bilstm_path, logger)\n",
        "\n",
        "#     if lstm_model is None or bilstm_model is None:\n",
        "#         raise RuntimeError(\"Failed to load models\")\n",
        "\n",
        "#     # Load scaler\n",
        "#     scaler_data = np.load(scaler_path)\n",
        "#     scaler = MinMaxScaler()\n",
        "#     scaler.min_ = scaler_data['min']\n",
        "#     scaler.scale_ = scaler_data['scale']\n",
        "\n",
        "#     return lstm_model, bilstm_model, scaler\n",
        "\n",
        "# def ensemble_predict(lstm_model, bilstm_model, X):\n",
        "#     \"\"\"Ensemble prediction from both models\"\"\"\n",
        "#     pred_lstm = lstm_model.predict(X, verbose=0).flatten()\n",
        "#     pred_bilstm = bilstm_model.predict(X, verbose=0).flatten()\n",
        "#     return (pred_lstm + pred_bilstm) / 2.0\n",
        "\n",
        "# # ---------------- UI FUNCTIONS ----------------\n",
        "# def start_training(symbol):\n",
        "#     \"\"\"Start training in background\"\"\"\n",
        "#     if TRAINING_FLAGS.get(symbol, False):\n",
        "#         return f\"âš ï¸ Training already running for {symbol}\"\n",
        "\n",
        "#     thread = threading.Thread(target=train_models_thread, args=(symbol,), daemon=True)\n",
        "#     thread.start()\n",
        "\n",
        "#     return f\"ðŸš€ Started training for {symbol}. Check logs below...\"\n",
        "\n",
        "# def get_training_logs(symbol):\n",
        "#     \"\"\"Retrieve training logs\"\"\"\n",
        "#     if symbol in TRAINING_FLAGS and TRAINING_FLAGS[symbol]:\n",
        "#         status = \"ðŸ”„ Training in progress...\\n\\n\"\n",
        "#     else:\n",
        "#         status = \"âœ… Training completed (or not started)\\n\\n\"\n",
        "\n",
        "#     logs = TRAIN_LOGS.get(symbol, \"No logs yet. Click 'Train Models' to start.\")\n",
        "#     return status + logs\n",
        "\n",
        "# def make_prediction(symbol):\n",
        "#     \"\"\"Make a single prediction\"\"\"\n",
        "#     try:\n",
        "#         if not is_trained(symbol):\n",
        "#             return f\"âŒ Models not trained for {symbol}. Train first!\"\n",
        "\n",
        "#         # Load models\n",
        "#         lstm_model, bilstm_model, scaler = load_models_and_scaler(symbol)\n",
        "\n",
        "#         # Get recent data\n",
        "#         df = download_stock_data(symbol, period='3mo')\n",
        "#         df = add_technical_indicators(df)\n",
        "\n",
        "#         X, y, _, _ = prepare_sequences(df, SEQ_LEN)\n",
        "\n",
        "#         if len(X) == 0:\n",
        "#             return \"âŒ Insufficient data for prediction\"\n",
        "\n",
        "#         # Get last sequence\n",
        "#         last_seq = X[-1:]\n",
        "\n",
        "#         # Predict\n",
        "#         pred_scaled = ensemble_predict(lstm_model, bilstm_model, last_seq)[0]\n",
        "\n",
        "#         # Inverse transform\n",
        "#         dummy = np.zeros((1, scaler.scale_.shape[0]))\n",
        "#         dummy[0, 0] = pred_scaled\n",
        "#         pred_price = scaler.inverse_transform(dummy)[0, 0]\n",
        "\n",
        "#         # Current price\n",
        "#         current_price = df['Close'].values[-1]\n",
        "#         change_pct = ((pred_price - current_price) / current_price) * 100\n",
        "\n",
        "#         result = f\"\"\"ðŸ“Š **Prediction for {symbol}**\n",
        "\n",
        "# Current Price: ${current_price:.2f}\n",
        "# Predicted Next: ${pred_price:.2f}\n",
        "# Expected Change: {change_pct:+.2f}%\n",
        "\n",
        "# ðŸ¤– Ensemble: LSTM + Bidirectional LSTM\n",
        "# \"\"\"\n",
        "#         return result\n",
        "\n",
        "#     except Exception as e:\n",
        "#         return f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "# def get_validation_plot(symbol):\n",
        "#     \"\"\"Generate validation plot\"\"\"\n",
        "#     try:\n",
        "#         if not is_trained(symbol):\n",
        "#             fig = plt.figure(figsize=(10, 4))\n",
        "#             plt.text(0.5, 0.5, f\"Models not trained for {symbol}\\nClick 'Train Models' first\",\n",
        "#                     ha='center', va='center', fontsize=14)\n",
        "#             plt.axis('off')\n",
        "#             return fig\n",
        "\n",
        "#         # Load models\n",
        "#         lstm_model, bilstm_model, scaler = load_models_and_scaler(symbol)\n",
        "\n",
        "#         # Get data\n",
        "#         df = download_stock_data(symbol, period='6mo')\n",
        "#         df = add_technical_indicators(df)\n",
        "#         X, y, _, _ = prepare_sequences(df, SEQ_LEN)\n",
        "\n",
        "#         # Use last 20% as test\n",
        "#         split_idx = int(len(X) * 0.8)\n",
        "#         X_test = X[split_idx:]\n",
        "#         y_test = y[split_idx:]\n",
        "\n",
        "#         # Predict\n",
        "#         pred_scaled = ensemble_predict(lstm_model, bilstm_model, X_test)\n",
        "\n",
        "#         # Inverse transform\n",
        "#         dummy_pred = np.zeros((len(pred_scaled), scaler.scale_.shape[0]))\n",
        "#         dummy_pred[:, 0] = pred_scaled\n",
        "#         pred_prices = scaler.inverse_transform(dummy_pred)[:, 0]\n",
        "\n",
        "#         dummy_actual = np.zeros((len(y_test), scaler.scale_.shape[0]))\n",
        "#         dummy_actual[:, 0] = y_test\n",
        "#         actual_prices = scaler.inverse_transform(dummy_actual)[:, 0]\n",
        "\n",
        "#         # Plot\n",
        "#         fig = plt.figure(figsize=(12, 5))\n",
        "#         plt.plot(actual_prices, label='Actual', linewidth=2, color='blue')\n",
        "#         plt.plot(pred_prices, label='Predicted', linewidth=2, color='red', alpha=0.7)\n",
        "#         plt.title(f'{symbol} - Validation: Actual vs Predicted', fontsize=14, fontweight='bold')\n",
        "#         plt.xlabel('Time Steps')\n",
        "#         plt.ylabel('Price ($)')\n",
        "#         plt.legend()\n",
        "#         plt.grid(True, alpha=0.3)\n",
        "#         plt.tight_layout()\n",
        "\n",
        "#         return fig\n",
        "\n",
        "#     except Exception as e:\n",
        "#         fig = plt.figure(figsize=(10, 4))\n",
        "#         plt.text(0.5, 0.5, f\"Error generating plot:\\n{str(e)}\",\n",
        "#                 ha='center', va='center', fontsize=12)\n",
        "#         plt.axis('off')\n",
        "#         return fig\n",
        "\n",
        "# def download_model_files(symbol):\n",
        "#     \"\"\"Provide download links for models\"\"\"\n",
        "#     if not is_trained(symbol):\n",
        "#         return None, None, None\n",
        "\n",
        "#     lstm_path = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "#     bilstm_path = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "#     scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.npz\")\n",
        "\n",
        "#     # Create zip files for SavedModel directories\n",
        "#     import shutil\n",
        "#     lstm_zip = f\"{lstm_path}.zip\"\n",
        "#     bilstm_zip = f\"{bilstm_path}.zip\"\n",
        "\n",
        "#     if not os.path.exists(lstm_zip):\n",
        "#         shutil.make_archive(lstm_path, 'zip', lstm_path)\n",
        "#     if not os.path.exists(bilstm_zip):\n",
        "#         shutil.make_archive(bilstm_path, 'zip', bilstm_path)\n",
        "\n",
        "#     return lstm_zip, bilstm_zip, scaler_path\n",
        "\n",
        "# # ---------------- GRADIO INTERFACE ----------------\n",
        "# with gr.Blocks(theme=gr.themes.Soft(), title=\"Stock Predictor\") as app:\n",
        "#     gr.Markdown(\"\"\"\n",
        "#     # ðŸ“ˆ Stock Price Predictor\n",
        "#     ### LSTM + Bidirectional LSTM Ensemble Model\n",
        "#     Train models on historical data and predict future stock prices\n",
        "#     \"\"\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         stock_dropdown = gr.Dropdown(\n",
        "#             choices=TOP_10_STOCKS,\n",
        "#             value=\"AAPL\",\n",
        "#             label=\"ðŸ“Š Select Stock\",\n",
        "#             interactive=True\n",
        "#         )\n",
        "#         train_button = gr.Button(\"ðŸš€ Train Models\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         logs_display = gr.Textbox(\n",
        "#             label=\"ðŸ“‹ Training Logs\",\n",
        "#             lines=12,\n",
        "#             max_lines=20,\n",
        "#             interactive=False\n",
        "#         )\n",
        "#         refresh_logs_btn = gr.Button(\"ðŸ”„ Refresh Logs\")\n",
        "\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸŽ¯ Make Predictions\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         predict_button = gr.Button(\"ðŸ”® Predict Next Price\", variant=\"secondary\", size=\"lg\")\n",
        "#         prediction_output = gr.Textbox(\n",
        "#             label=\"Prediction Result\",\n",
        "#             lines=7,\n",
        "#             interactive=False\n",
        "#         )\n",
        "\n",
        "#     with gr.Row():\n",
        "#         validation_plot = gr.Plot(label=\"ðŸ“Š Validation Plot (Actual vs Predicted)\")\n",
        "\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸ’¾ Download Trained Models\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         lstm_download = gr.File(label=\"LSTM Model (ZIP)\")\n",
        "#         bilstm_download = gr.File(label=\"Bidirectional LSTM Model (ZIP)\")\n",
        "#         scaler_download = gr.File(label=\"Scaler Data\")\n",
        "\n",
        "#     # Event handlers\n",
        "#     train_button.click(\n",
        "#         fn=start_training,\n",
        "#         inputs=[stock_dropdown],\n",
        "#         outputs=[logs_display]\n",
        "#     )\n",
        "\n",
        "#     refresh_logs_btn.click(\n",
        "#         fn=get_training_logs,\n",
        "#         inputs=[stock_dropdown],\n",
        "#         outputs=[logs_display]\n",
        "#     )\n",
        "\n",
        "#     predict_button.click(\n",
        "#         fn=make_prediction,\n",
        "#         inputs=[stock_dropdown],\n",
        "#         outputs=[prediction_output]\n",
        "#     )\n",
        "\n",
        "#     stock_dropdown.change(\n",
        "#         fn=get_validation_plot,\n",
        "#         inputs=[stock_dropdown],\n",
        "#         outputs=[validation_plot]\n",
        "#     )\n",
        "\n",
        "#     stock_dropdown.change(\n",
        "#         fn=download_model_files,\n",
        "#         inputs=[stock_dropdown],\n",
        "#         outputs=[lstm_download, bilstm_download, scaler_download]\n",
        "#     )\n",
        "\n",
        "# # Launch app\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"=\" * 50)\n",
        "#     print(\"ðŸš€ Stock Predictor App Starting...\")\n",
        "#     print(\"=\" * 50)\n",
        "#     app.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "uGQvsZiumPde",
        "outputId": "49c66583-a7b2-4cf4-c8e1-043932451a97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "ðŸš€ Stock Predictor App Starting...\n",
            "==================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://31de3ab31abc668c48.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://31de3ab31abc668c48.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MnQhhD7FiYgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rb8obF12iYl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irCORfiRiYpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKD7yRoXiYts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CmY0dcAQiYxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61pSSkz8iY12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Full Gradio stock predictor app (LSTM + Transformer ensemble, indicators, polling live prices)\n",
        "# # FIXED VERSION - All errors resolved\n",
        "\n",
        "# import os, time, threading, io, traceback\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import yfinance as yf\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models, callbacks\n",
        "# import matplotlib.pyplot as plt\n",
        "# import gradio as gr\n",
        "# import ta\n",
        "\n",
        "# # ---------------- CONFIG ----------------\n",
        "# TOP_10_STOCKS = [\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\"NFLX\",\"JPM\",\"AMD\"]\n",
        "# MODELS_DIR = \"/content/stock_models\"\n",
        "# os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# SEQ_LEN = 20             # ULTRA-FAST: Reduced from 60\n",
        "# POLL_INTERVAL = 8        # seconds for live polling\n",
        "# EPOCHS_REG = 2           # ULTRA-FAST: Minimal epochs for speed\n",
        "# EPOCHS_CLS = 1           # ULTRA-FAST: Single epoch\n",
        "# BATCH_SIZE = 128         # ULTRA-FAST: Large batches\n",
        "\n",
        "# # Shared state\n",
        "# LIVE_STATE = {}\n",
        "# POLLERS = {}\n",
        "# TRAIN_LOGS = {}       # summary logs stored after training finish\n",
        "# TRAINING_FLAGS = {}   # symbol -> bool (training running)\n",
        "\n",
        "# # ---------------- UTIL: safe model save/load ----------------\n",
        "# def compile_model_for_saving(model):\n",
        "#     # compile model with explicit objects to avoid short-name issues on load\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "#                   loss=tf.keras.losses.MeanSquaredError(),\n",
        "#                   metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "#     return model\n",
        "\n",
        "# def safe_save_model(model, path):\n",
        "#     \"\"\"Save model in SavedModel format (directory) instead of H5\"\"\"\n",
        "#     compile_model_for_saving(model)\n",
        "#     # Use .keras format (TF 2.x native format) instead of legacy H5\n",
        "#     keras_path = path.replace('.h5', '.keras')\n",
        "#     model.save(keras_path, save_format='keras')\n",
        "#     return keras_path\n",
        "\n",
        "# def safe_load_model(path):\n",
        "#     \"\"\"Load model from .keras format with fallback to H5\"\"\"\n",
        "#     keras_path = path.replace('.h5', '.keras')\n",
        "\n",
        "#     # Try .keras format first\n",
        "#     if os.path.exists(keras_path):\n",
        "#         try:\n",
        "#             return tf.keras.models.load_model(keras_path)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Failed to load .keras format: {e}\")\n",
        "\n",
        "#     # Fallback to H5 format\n",
        "#     if os.path.exists(path):\n",
        "#         try:\n",
        "#             return tf.keras.models.load_model(path, compile=False)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Model load failed: {e}\")\n",
        "#             traceback.print_exc()\n",
        "\n",
        "#     return None\n",
        "\n",
        "# # ---------------- DATA & FEATURES ----------------\n",
        "# def get_stock_history(symbol, period='4y', interval='1d'):\n",
        "#     \"\"\"\n",
        "#     FIX #1: Properly handle yfinance DataFrame and ensure Close is 1D Series\n",
        "#     FIX #3: Add auto_adjust parameter explicitly\n",
        "#     \"\"\"\n",
        "#     # Download with explicit auto_adjust parameter to avoid warning\n",
        "#     df = yf.download(symbol, period=period, interval=interval, progress=False, auto_adjust=True)\n",
        "\n",
        "#     # Handle multi-level columns if present\n",
        "#     if isinstance(df.columns, pd.MultiIndex):\n",
        "#         df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "#     df = df[['Open','High','Low','Close','Volume']].copy()\n",
        "#     df = df.dropna()\n",
        "\n",
        "#     # CRITICAL FIX: Ensure Close column is 1D Series, not 2D DataFrame\n",
        "#     if isinstance(df['Close'], pd.DataFrame):\n",
        "#         df['Close'] = df['Close'].iloc[:, 0]\n",
        "\n",
        "#     # Convert to Series if it's still not\n",
        "#     close_series = pd.Series(df['Close'].values.flatten(), index=df.index)\n",
        "\n",
        "#     # Technical indicators - pass Series explicitly\n",
        "#     df['SMA_10'] = close_series.rolling(10).mean()\n",
        "#     df['EMA_10'] = close_series.ewm(span=10, adjust=False).mean()\n",
        "\n",
        "#     # RSI - ensure input is 1D\n",
        "#     df['RSI_14'] = ta.momentum.rsi(close_series, window=14)\n",
        "\n",
        "#     # MACD - ensure input is 1D\n",
        "#     macd = ta.trend.MACD(close_series)\n",
        "#     df['MACD'] = macd.macd()\n",
        "#     df['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "#     df.dropna(inplace=True)\n",
        "#     return df\n",
        "\n",
        "# def prepare_sequences(df, feature_cols=None, seq_len=SEQ_LEN):\n",
        "#     if feature_cols is None:\n",
        "#         feature_cols = ['Close','SMA_10','EMA_10','RSI_14','MACD','MACD_signal','Volume']\n",
        "\n",
        "#     # Ensure all features are present\n",
        "#     missing_cols = [col for col in feature_cols if col not in df.columns]\n",
        "#     if missing_cols:\n",
        "#         print(f\"Warning: Missing columns {missing_cols}, using available columns only\")\n",
        "#         feature_cols = [col for col in feature_cols if col in df.columns]\n",
        "\n",
        "#     arr = df[feature_cols].values.astype(np.float32)\n",
        "#     scaler = MinMaxScaler()\n",
        "#     scaled = scaler.fit_transform(arr)\n",
        "#     X, y_reg, y_trend = [], [], []\n",
        "#     for i in range(seq_len, len(scaled)):\n",
        "#         X.append(scaled[i-seq_len:i])\n",
        "#         y_reg.append(scaled[i][0])  # close at index 0\n",
        "#         y_trend.append(1 if scaled[i][0] > scaled[i-1][0] else 0)\n",
        "#     return np.array(X), np.array(y_reg), np.array(y_trend), scaler\n",
        "\n",
        "# # ---------------- MODEL ARCHITECTURES ----------------\n",
        "# def build_lstm(seq_len=SEQ_LEN, features=7):\n",
        "#     \"\"\"Ultra-fast LSTM - minimal architecture\"\"\"\n",
        "#     inp = layers.Input(shape=(seq_len, features))\n",
        "#     x = layers.LSTM(32)(inp)  # Single LSTM layer, reduced size\n",
        "#     x = layers.Dense(16, activation='relu')(x)\n",
        "#     out = layers.Dense(1)(x)\n",
        "#     model = models.Model(inp, out)\n",
        "#     model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
        "#     return model\n",
        "\n",
        "# def build_transformer(seq_len=SEQ_LEN, features=7, d_model=16, heads=2, ff_dim=32):\n",
        "#     \"\"\"Ultra-fast Transformer - minimal architecture\"\"\"\n",
        "#     inputs = layers.Input(shape=(seq_len, features))\n",
        "#     x = layers.Dense(d_model)(inputs)\n",
        "#     # Single attention block\n",
        "#     attn = layers.MultiHeadAttention(num_heads=heads, key_dim=d_model)(x, x)\n",
        "#     x = layers.Add()([x, attn])\n",
        "#     x = layers.LayerNormalization()(x)\n",
        "#     x = layers.GlobalAveragePooling1D()(x)\n",
        "#     x = layers.Dense(16, activation='relu')(x)\n",
        "#     outputs = layers.Dense(1)(x)\n",
        "#     model = models.Model(inputs, outputs)\n",
        "#     model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
        "#     return model\n",
        "\n",
        "# def build_classifier(seq_len=SEQ_LEN, features=7):\n",
        "#     \"\"\"Ultra-fast Classifier - minimal architecture\"\"\"\n",
        "#     inputs = layers.Input(shape=(seq_len, features))\n",
        "#     x = layers.LSTM(32)(inputs)  # Single LSTM\n",
        "#     x = layers.Dense(16, activation='relu')(x)\n",
        "#     outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "#     model = models.Model(inputs, outputs)\n",
        "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# # ---------------- TRAINING (background thread) ----------------\n",
        "# def train_models_thread(symbol, epochs_reg=EPOCHS_REG, epochs_cls=EPOCHS_CLS):\n",
        "#     \"\"\"\n",
        "#     Train LSTM, Transformer, Classifier in a background thread.\n",
        "#     Store final logs to TRAIN_LOGS[symbol].\n",
        "#     \"\"\"\n",
        "#     TRAINING_FLAGS[symbol] = True\n",
        "#     logs = []\n",
        "#     def log(s):\n",
        "#         ts = time.strftime(\"%H:%M:%S\")\n",
        "#         line = f\"[{ts}] {s}\"\n",
        "#         logs.append(line)\n",
        "#         TRAIN_LOGS[symbol] = \"\\n\".join(logs)\n",
        "#         print(line)\n",
        "\n",
        "#     try:\n",
        "#         log(f\"Downloading {symbol} data...\")\n",
        "#         # ULTRA-FAST: Only 1 year of data\n",
        "#         df = get_stock_history(symbol, period='1y', interval='1d')\n",
        "#         log(f\"âœ“ Downloaded {len(df)} rows\")\n",
        "#         X, y_reg, y_trend, scaler = prepare_sequences(df)\n",
        "#         if len(X) < 50:  # Very low threshold\n",
        "#             raise RuntimeError(f\"Not enough training rows ({len(X)}). Need at least 50.\")\n",
        "\n",
        "#         split = int(len(X) * 0.8)\n",
        "#         X_train, X_val = X[:split], X[split:]\n",
        "#         y_train, y_val = y_reg[:split], y_reg[split:]\n",
        "#         y_train_tr, y_val_tr = y_trend[:split], y_trend[split:]\n",
        "#         log(f\"âœ“ Prepared {len(X_train)} training samples, {len(X_val)} validation samples\")\n",
        "\n",
        "#         # LSTM\n",
        "#         log(\"Building LSTM...\")\n",
        "#         lstm = build_lstm(seq_len=SEQ_LEN, features=X.shape[2])\n",
        "#         log(f\"Training LSTM ({epochs_reg} epochs)... â³\")\n",
        "#         history = lstm.fit(X_train, y_train, validation_data=(X_val,y_val),\n",
        "#                           epochs=epochs_reg, batch_size=BATCH_SIZE, verbose=0)\n",
        "#         log(f\"âœ“ LSTM trained! Final loss: {history.history['loss'][-1]:.4f}\")\n",
        "#         lstm_path = os.path.join(MODELS_DIR, f\"{symbol}_lstm.h5\")\n",
        "#         saved_path = safe_save_model(lstm, lstm_path)\n",
        "#         log(f\"âœ“ LSTM saved\")\n",
        "\n",
        "#         # Transformer\n",
        "#         log(\"Building Transformer...\")\n",
        "#         trans = build_transformer(seq_len=SEQ_LEN, features=X.shape[2])\n",
        "#         log(f\"Training Transformer ({epochs_reg} epochs)... â³\")\n",
        "#         history = trans.fit(X_train, y_train, validation_data=(X_val,y_val),\n",
        "#                            epochs=epochs_reg, batch_size=BATCH_SIZE, verbose=0)\n",
        "#         log(f\"âœ“ Transformer trained! Final loss: {history.history['loss'][-1]:.4f}\")\n",
        "#         trans_path = os.path.join(MODELS_DIR, f\"{symbol}_trans.h5\")\n",
        "#         saved_path = safe_save_model(trans, trans_path)\n",
        "#         log(f\"âœ“ Transformer saved\")\n",
        "\n",
        "#         # Classifier\n",
        "#         log(\"Building classifier...\")\n",
        "#         cls = build_classifier(seq_len=SEQ_LEN, features=X.shape[2])\n",
        "#         log(f\"Training Classifier ({epochs_cls} epoch)... â³\")\n",
        "#         history = cls.fit(X_train, y_train_tr, validation_data=(X_val, y_val_tr),\n",
        "#                          epochs=epochs_cls, batch_size=BATCH_SIZE, verbose=0)\n",
        "#         log(f\"âœ“ Classifier trained! Accuracy: {history.history.get('val_accuracy', [0])[-1]:.2%}\")\n",
        "#         cls_path = os.path.join(MODELS_DIR, f\"{symbol}_cls.h5\")\n",
        "#         saved_path = safe_save_model(cls, cls_path)\n",
        "#         log(f\"âœ“ Classifier saved\")\n",
        "\n",
        "#         # Scaler: save min and scale arrays (so we can inverse transform close)\n",
        "#         scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.npy\")\n",
        "#         np.save(scaler_path, np.array([scaler.min_, scaler.scale_], dtype=object), allow_pickle=True)\n",
        "#         log(f\"âœ“ Scaler saved\")\n",
        "\n",
        "#         log(\"ðŸŽ‰ Training completed successfully!\")\n",
        "#         log(f\"â±ï¸ Total time: ~30-60 seconds\")\n",
        "#     except Exception as e:\n",
        "#         log(f\"Training failed: {e}\")\n",
        "#         traceback.print_exc()\n",
        "#     finally:\n",
        "#         TRAINING_FLAGS[symbol] = False\n",
        "#         TRAIN_LOGS[symbol] = \"\\n\".join(logs)\n",
        "\n",
        "# def start_training(symbol):\n",
        "#     if TRAINING_FLAGS.get(symbol, False):\n",
        "#         return \"Training already running for \" + symbol\n",
        "#     t = threading.Thread(target=train_models_thread, args=(symbol,), daemon=True)\n",
        "#     t.start()\n",
        "#     return \"Started background training for \" + symbol\n",
        "\n",
        "# # ---------------- helper: check trained and load models ----------------\n",
        "# def is_trained(symbol):\n",
        "#     \"\"\"Check if all model files exist (both .keras and .h5 formats)\"\"\"\n",
        "#     base_path = os.path.join(MODELS_DIR, symbol)\n",
        "\n",
        "#     # Check for .keras format first (preferred)\n",
        "#     keras_exists = (\n",
        "#         os.path.exists(f\"{base_path}_lstm.keras\") and\n",
        "#         os.path.exists(f\"{base_path}_trans.keras\") and\n",
        "#         os.path.exists(f\"{base_path}_cls.keras\") and\n",
        "#         os.path.exists(f\"{base_path}_scaler.npy\")\n",
        "#     )\n",
        "\n",
        "#     # Fallback to .h5 format\n",
        "#     h5_exists = (\n",
        "#         os.path.exists(f\"{base_path}_lstm.h5\") and\n",
        "#         os.path.exists(f\"{base_path}_trans.h5\") and\n",
        "#         os.path.exists(f\"{base_path}_cls.h5\") and\n",
        "#         os.path.exists(f\"{base_path}_scaler.npy\")\n",
        "#     )\n",
        "\n",
        "#     return keras_exists or h5_exists\n",
        "\n",
        "# def load_models(symbol):\n",
        "#     \"\"\"FIX #2: Improved model loading with better error handling\"\"\"\n",
        "#     lstm = safe_load_model(os.path.join(MODELS_DIR, f\"{symbol}_lstm.h5\"))\n",
        "#     trans = safe_load_model(os.path.join(MODELS_DIR, f\"{symbol}_trans.h5\"))\n",
        "#     cls = safe_load_model(os.path.join(MODELS_DIR, f\"{symbol}_cls.h5\"))\n",
        "\n",
        "#     if lstm is None or trans is None or cls is None:\n",
        "#         raise RuntimeError(f\"Failed to load one or more models for {symbol}\")\n",
        "\n",
        "#     # load scaler\n",
        "#     arr = np.load(os.path.join(MODELS_DIR, f\"{symbol}_scaler.npy\"), allow_pickle=True)\n",
        "#     min_, scale_ = arr\n",
        "\n",
        "#     class ScalerWrap:\n",
        "#         def __init__(self, min_, scale_):\n",
        "#             self.min_ = np.array(min_, dtype=np.float32)\n",
        "#             self.scale_ = np.array(scale_, dtype=np.float32)\n",
        "#         def inv_close(self, scaled_close):\n",
        "#             # scaled_close may be numpy array shape (n,1) or scalar\n",
        "#             scaled_arr = np.atleast_1d(scaled_close)\n",
        "#             return scaled_arr / self.scale_[0] + self.min_[0]\n",
        "\n",
        "#     scl = ScalerWrap(min_, scale_)\n",
        "#     return lstm, trans, cls, scl\n",
        "\n",
        "# # ---------------- prediction helpers ----------------\n",
        "# def ensemble_predict(lstm, trans, X):\n",
        "#     p1 = lstm.predict(X, verbose=0).reshape(-1)\n",
        "#     p2 = trans.predict(X, verbose=0).reshape(-1)\n",
        "#     return (p1 + p2) / 2.0\n",
        "\n",
        "# # ---------------- plotting helpers (always return matplotlib.figure) ----------------\n",
        "# def plot_pred_vs_actual(actual, pred, title=\"Predicted vs Actual\"):\n",
        "#     fig = plt.figure(figsize=(10,4))\n",
        "#     plt.plot(actual, label='Actual', linewidth=2)\n",
        "#     plt.plot(pred, label='Predicted', linewidth=2, alpha=0.8)\n",
        "#     plt.legend()\n",
        "#     plt.title(title)\n",
        "#     plt.xlabel('Time')\n",
        "#     plt.ylabel('Price')\n",
        "#     plt.grid(True, alpha=0.3)\n",
        "#     plt.tight_layout()\n",
        "#     return fig\n",
        "\n",
        "# # ---------------- validation graph function ----------------\n",
        "# def get_validation_figure(symbol):\n",
        "#     if not is_trained(symbol):\n",
        "#         # return a neutral figure urging training\n",
        "#         fig = plt.figure(figsize=(8,3))\n",
        "#         plt.text(0.5, 0.5, \"Models not trained yet.\\nClick 'Train (background)' button.\",\n",
        "#                 ha='center', va='center', fontsize=14)\n",
        "#         plt.axis('off')\n",
        "#         return fig\n",
        "\n",
        "#     try:\n",
        "#         lstm, trans, cls, scl = load_models(symbol)\n",
        "#         df = get_stock_history(symbol, period='3y', interval='1d')\n",
        "#         X, y_reg, y_trend, scaler = prepare_sequences(df)\n",
        "#         if len(X) == 0:\n",
        "#             fig = plt.figure(figsize=(8,3))\n",
        "#             plt.text(0.5,0.5,\"Not enough data for validation plot.\", ha='center', va='center')\n",
        "#             plt.axis('off')\n",
        "#             return fig\n",
        "\n",
        "#         split = int(len(X) * 0.8)\n",
        "#         X_val = X[split:]\n",
        "#         y_val = y_reg[split:]\n",
        "#         scaled_preds = ensemble_predict(lstm, trans, X_val)\n",
        "\n",
        "#         # Inverse transform\n",
        "#         preds = scaler.inverse_transform(scaled_preds.reshape(-1,1)).reshape(-1)\n",
        "#         actuals = scaler.inverse_transform(y_val.reshape(-1,1)).reshape(-1)\n",
        "\n",
        "#         return plot_pred_vs_actual(actuals, preds, title=f\"{symbol} Validation\")\n",
        "#     except Exception as e:\n",
        "#         fig = plt.figure(figsize=(8,3))\n",
        "#         plt.text(0.5, 0.5, f\"Error generating plot:\\n{str(e)}\",\n",
        "#                 ha='center', va='center', fontsize=10)\n",
        "#         plt.axis('off')\n",
        "#         return fig\n",
        "\n",
        "# # ---------------- live poller (yfinance) ----------------\n",
        "# def poller(symbol, stop_event):\n",
        "#     # ensure model trained\n",
        "#     if not is_trained(symbol):\n",
        "#         # train synchronously to avoid poller running with no model\n",
        "#         train_models_thread(symbol)\n",
        "#         # after training returns, continue (or abort if missing)\n",
        "\n",
        "#     try:\n",
        "#         lstm, trans, cls, scl = load_models(symbol)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Poller failed to load models: {e}\")\n",
        "#         LIVE_STATE.pop(symbol, None)\n",
        "#         return\n",
        "\n",
        "#     while not stop_event.is_set():\n",
        "#         try:\n",
        "#             # try 1m if available, else daily\n",
        "#             df = yf.download(symbol, period='5d', interval='1m', progress=False, auto_adjust=True)\n",
        "#             if df.empty:\n",
        "#                 df = get_stock_history(symbol, period='6mo', interval='1d')\n",
        "#             else:\n",
        "#                 # Handle multi-level columns\n",
        "#                 if isinstance(df.columns, pd.MultiIndex):\n",
        "#                     df.columns = df.columns.get_level_values(0)\n",
        "#                 df = df[['Open','High','Low','Close','Volume']].dropna()\n",
        "\n",
        "#             # prepare feature df\n",
        "#             df_full = get_stock_history(symbol, period='6mo', interval='1d')\n",
        "#             X, y_reg, y_trend, scaler = prepare_sequences(df_full)\n",
        "#             if len(X) < 1:\n",
        "#                 time.sleep(POLL_INTERVAL)\n",
        "#                 continue\n",
        "\n",
        "#             last = X[-1].reshape(1, X.shape[1], X.shape[2])\n",
        "#             scaled_pred = ensemble_predict(lstm, trans, last)[0]\n",
        "#             pred_price = scl.inv_close(np.array([[scaled_pred]]))[0]\n",
        "\n",
        "#             LIVE_STATE[symbol] = {\n",
        "#                 'timestamp': time.time(),\n",
        "#                 'pred_price': float(pred_price),\n",
        "#                 'actual_price': float(df['Close'].values[-1]),\n",
        "#                 'history_df': df_full.tail(300)\n",
        "#             }\n",
        "#         except Exception as e:\n",
        "#             print(f\"Poller error for {symbol}: {e}\")\n",
        "\n",
        "#         time.sleep(POLL_INTERVAL)\n",
        "\n",
        "# def start_poller(symbol):\n",
        "#     if symbol in POLLERS:\n",
        "#         return f\"Poller already running for {symbol}\"\n",
        "#     if not is_trained(symbol):\n",
        "#         return f\"Models not trained for {symbol}. Train first!\"\n",
        "\n",
        "#     stop_event = threading.Event()\n",
        "#     t = threading.Thread(target=poller, args=(symbol, stop_event), daemon=True)\n",
        "#     POLLERS[symbol] = {'thread': t, 'stop': stop_event}\n",
        "#     t.start()\n",
        "#     return f\"Started live poller for {symbol}\"\n",
        "\n",
        "# def stop_poller(symbol):\n",
        "#     if symbol not in POLLERS:\n",
        "#         return f\"No poller running for {symbol}\"\n",
        "#     POLLERS[symbol]['stop'].set()\n",
        "#     time.sleep(0.5)\n",
        "#     del POLLERS[symbol]\n",
        "#     return f\"Stopped poller for {symbol}\"\n",
        "\n",
        "# def get_live_figure(symbol):\n",
        "#     s = LIVE_STATE.get(symbol)\n",
        "#     if not s:\n",
        "#         fig = plt.figure(figsize=(8,3))\n",
        "#         plt.text(0.5,0.5, \"No live data yet.\\nStart Poller first.\", ha='center', va='center', fontsize=12)\n",
        "#         plt.axis('off')\n",
        "#         return fig\n",
        "\n",
        "#     df = s.get('history_df')\n",
        "#     if df is None or df.empty:\n",
        "#         fig = plt.figure(figsize=(8,3))\n",
        "#         plt.text(0.5,0.5,\"No history available\", ha='center', va='center')\n",
        "#         plt.axis('off')\n",
        "#         return fig\n",
        "\n",
        "#     close = df['Close'].values\n",
        "#     fig = plt.figure(figsize=(10,4))\n",
        "#     plt.plot(close, label='Recent Close', linewidth=2)\n",
        "#     plt.scatter([len(close)-1], [s['pred_price']], color='red', s=100,\n",
        "#                label=f\"Predicted: ${s['pred_price']:.2f}\", zorder=5)\n",
        "#     plt.legend()\n",
        "#     plt.title(f\"{symbol} Live (recent closes + current prediction)\")\n",
        "#     plt.xlabel('Time')\n",
        "#     plt.ylabel('Price ($)')\n",
        "#     plt.grid(True, alpha=0.3)\n",
        "#     plt.tight_layout()\n",
        "#     return fig\n",
        "\n",
        "# # ---------------- single prediction ----------------\n",
        "# def single_prediction(symbol):\n",
        "#     if not is_trained(symbol):\n",
        "#         return f\"âš ï¸ Models not trained for {symbol}. Click 'Train (background)' first.\"\n",
        "\n",
        "#     try:\n",
        "#         lstm, trans, cls, scl = load_models(symbol)\n",
        "#         df = get_stock_history(symbol, period='6mo', interval='1d')\n",
        "#         X, y_reg, y_trend, scaler = prepare_sequences(df)\n",
        "#         if len(X) == 0:\n",
        "#             return \"Not enough data to predict.\"\n",
        "\n",
        "#         last = X[-1].reshape(1, X.shape[1], X.shape[2])\n",
        "#         scaled_pred = ensemble_predict(lstm, trans, last)[0]\n",
        "#         pred_price = scl.inv_close(np.array([[scaled_pred]]))[0]\n",
        "\n",
        "#         # Get current price\n",
        "#         current_price = df['Close'].values[-1]\n",
        "#         change = ((pred_price - current_price) / current_price) * 100\n",
        "\n",
        "#         return (f\"ðŸ“Š Prediction for {symbol}\\n\"\n",
        "#                f\"Current Price: ${current_price:.2f}\\n\"\n",
        "#                f\"Predicted Next Close: ${pred_price:.2f}\\n\"\n",
        "#                f\"Expected Change: {change:+.2f}%\")\n",
        "#     except Exception as e:\n",
        "#         return f\"âŒ Error making prediction: {str(e)}\"\n",
        "\n",
        "# # ---------------- model download helper ----------------\n",
        "# def download_paths(symbol):\n",
        "#     if not is_trained(symbol):\n",
        "#         return (None, None, None, None)\n",
        "\n",
        "#     # Check for .keras files first\n",
        "#     base = os.path.join(MODELS_DIR, symbol)\n",
        "#     lstm_path = f\"{base}_lstm.keras\" if os.path.exists(f\"{base}_lstm.keras\") else f\"{base}_lstm.h5\"\n",
        "#     trans_path = f\"{base}_trans.keras\" if os.path.exists(f\"{base}_trans.keras\") else f\"{base}_trans.h5\"\n",
        "#     cls_path = f\"{base}_cls.keras\" if os.path.exists(f\"{base}_cls.keras\") else f\"{base}_cls.h5\"\n",
        "#     scaler_path = f\"{base}_scaler.npy\"\n",
        "\n",
        "#     return (lstm_path, trans_path, cls_path, scaler_path)\n",
        "\n",
        "# # ---------------- GRADIO UI ----------------\n",
        "# with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "#     gr.Markdown(\"# ðŸ“ˆ Top-10 Stock Predictor â€” Ensemble LSTM+Transformer\")\n",
        "#     gr.Markdown(\"Train models, make predictions, and monitor live stock prices with AI\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         stock_sel = gr.Dropdown(TOP_10_STOCKS, label=\"Select Stock Symbol\", value=\"AAPL\")\n",
        "#         train_btn = gr.Button(\"ðŸš€ Train (background)\", variant=\"primary\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         logs_box = gr.Textbox(label=\"Training Logs\", lines=10, max_lines=15)\n",
        "#         logs_refresh = gr.Button(\"ðŸ”„ Refresh Logs\")\n",
        "\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸ“Š Predictions\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         predict_btn = gr.Button(\"ðŸŽ¯ Single Prediction\", variant=\"secondary\")\n",
        "#         pred_box = gr.Textbox(label=\"Prediction Result\", lines=4)\n",
        "\n",
        "#     with gr.Row():\n",
        "#         val_plot = gr.Plot(label=\"Validation: Predicted vs Actual\")\n",
        "\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸ“¡ Live Monitoring\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         start_btn = gr.Button(\"â–¶ï¸ Start Live Polling\", variant=\"primary\")\n",
        "#         stop_btn = gr.Button(\"â¸ï¸ Stop Polling\", variant=\"stop\")\n",
        "#         live_refresh = gr.Button(\"ðŸ”„ Refresh Live Data\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         live_status = gr.Textbox(label=\"Live Status\", lines=3)\n",
        "#         live_plot = gr.Plot(label=\"Live Price Chart\")\n",
        "\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸ’¾ Download Trained Models\")\n",
        "\n",
        "#     with gr.Row():\n",
        "#         dl_lstm = gr.File(label=\"LSTM Model\")\n",
        "#         dl_trans = gr.File(label=\"Transformer Model\")\n",
        "#         dl_cls = gr.File(label=\"Classifier Model\")\n",
        "#         dl_scaler = gr.File(label=\"Scaler Data\")\n",
        "\n",
        "#     # Wire up all the interactions\n",
        "#     train_btn.click(fn=start_training, inputs=stock_sel, outputs=logs_box)\n",
        "\n",
        "#     def fetch_logs(symbol):\n",
        "#         return TRAIN_LOGS.get(symbol, \"No logs yet. Click 'Train (background)' to start.\")\n",
        "\n",
        "#     logs_refresh.click(fn=fetch_logs, inputs=stock_sel, outputs=logs_box)\n",
        "#     stock_sel.change(fn=get_validation_figure, inputs=stock_sel, outputs=val_plot)\n",
        "#     predict_btn.click(fn=single_prediction, inputs=stock_sel, outputs=pred_box)\n",
        "\n",
        "#     start_btn.click(fn=start_poller, inputs=stock_sel, outputs=live_status)\n",
        "#     stop_btn.click(fn=stop_poller, inputs=stock_sel, outputs=live_status)\n",
        "\n",
        "#     def live_status_and_plot(symbol):\n",
        "#         s = LIVE_STATE.get(symbol)\n",
        "#         if not s:\n",
        "#             return f\"No live data for {symbol}. Start poller first.\", get_live_figure(symbol)\n",
        "#         text = (f\"ðŸ“ {symbol} Live Data\\n\"\n",
        "#                 f\"Last Update: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(s['timestamp']))}\\n\"\n",
        "#                 f\"Current Price: ${s['actual_price']:.2f} | Predicted: ${s['pred_price']:.2f}\")\n",
        "#         return text, get_live_figure(symbol)\n",
        "\n",
        "#     live_refresh.click(fn=live_status_and_plot, inputs=stock_sel, outputs=[live_status, live_plot])\n",
        "#     stock_sel.change(fn=download_paths, inputs=stock_sel, outputs=[dl_lstm, dl_trans, dl_cls, dl_scaler])\n",
        "\n",
        "# # Launch Gradio app\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"ðŸš€ Starting Stock Predictor App...\")\n",
        "#     demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "5S9zaJbFmbB3",
        "outputId": "4bdb78c0-7917-4497-cbc5-5911fbabacd4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting Stock Predictor App...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9bd58ca319ddd73a1b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9bd58ca319ddd73a1b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Gu8-BzVqn9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cwUHvg2iayC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-CkZGcVia2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmUdErlVia6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zC9EHsDVia-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-YgMRytBibCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JUd6KkJoibGY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance gradio joblib tensorflow scikit-learn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRA-jLzJibKV",
        "outputId": "85c7e353-7eb9-42ef-d4d8-fb0557d603e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # FULLY DEBUGGED Stock Predictor - LSTM + Bidirectional LSTM Only\n",
        "# # Copy into Colab / local env and run. Requires: yfinance, tensorflow, scikit-learn, joblib, gradio, matplotlib, pandas, numpy\n",
        "\n",
        "# import os, time, threading, traceback, warnings, shutil\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import yfinance as yf\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# import joblib\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, models, callbacks\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')  # Non-interactive backend\n",
        "# import matplotlib.pyplot as plt\n",
        "# import gradio as gr\n",
        "\n",
        "# # Suppress warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# # ---------------- CONFIG ----------------\n",
        "# TOP_10_STOCKS = [\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\"NFLX\",\"JPM\",\"AMD\"]\n",
        "# MODELS_DIR = \"/content/stock_models\"\n",
        "# os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# # OPTIMIZED FOR SPEED (adjust for real training)\n",
        "# SEQ_LEN = 20\n",
        "# POLL_INTERVAL = 10\n",
        "# EPOCHS = 3\n",
        "# BATCH_SIZE = 64\n",
        "\n",
        "# # Shared state\n",
        "# LIVE_STATE = {}\n",
        "# POLLERS = {}\n",
        "# TRAIN_LOGS = {}\n",
        "# TRAINING_FLAGS = {}\n",
        "\n",
        "# # ---------------- LOGGING UTILITY ----------------\n",
        "# class Logger:\n",
        "#     def __init__(self, symbol):\n",
        "#         self.symbol = symbol\n",
        "#         self.logs = TRAIN_LOGS.get(symbol, []).copy() if isinstance(TRAIN_LOGS.get(symbol, []), list) else []\n",
        "#     def log(self, msg, level=\"INFO\"):\n",
        "#         timestamp = time.strftime(\"%H:%M:%S\")\n",
        "#         emoji = {\"INFO\": \"â„¹ï¸\", \"SUCCESS\": \"âœ…\", \"ERROR\": \"âŒ\", \"WARNING\": \"âš ï¸\"}.get(level, \"ðŸ“\")\n",
        "#         line = f\"[{timestamp}] {emoji} {msg}\"\n",
        "#         self.logs.append(line)\n",
        "#         TRAIN_LOGS[self.symbol] = self.logs\n",
        "#         # also return a human string\n",
        "#         print(line)\n",
        "#         return line\n",
        "\n",
        "# def logs_to_text(symbol):\n",
        "#     logs = TRAIN_LOGS.get(symbol, [])\n",
        "#     if not logs:\n",
        "#         return \"No logs yet. Click 'Train Models' to start.\"\n",
        "#     status = \"ðŸ”„ Training in progress...\\n\\n\" if TRAINING_FLAGS.get(symbol, False) else \"âœ… Training completed (or not started)\\n\\n\"\n",
        "#     return status + \"\\n\".join(logs)\n",
        "\n",
        "# # ---------------- DATA FUNCTIONS ----------------\n",
        "# def download_stock_data(symbol, period='1y', logger=None):\n",
        "#     try:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Downloading {symbol} data ({period})...\")\n",
        "#         df = yf.download(symbol, period=period, interval='1d', progress=False, auto_adjust=True, threads=False)\n",
        "#         if df is None or df.empty:\n",
        "#             raise ValueError(f\"No data returned for {symbol} (period={period})\")\n",
        "#         # if multiindex columns\n",
        "#         if isinstance(df.columns, pd.MultiIndex):\n",
        "#             df.columns = df.columns.get_level_values(0)\n",
        "#         required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "#         missing = [c for c in required_cols if c not in df.columns]\n",
        "#         if missing:\n",
        "#             raise ValueError(f\"Missing required columns from Yahoo: {missing}\")\n",
        "#         df = df[required_cols].copy()\n",
        "#         df = df.dropna()\n",
        "#         if logger:\n",
        "#             logger.log(f\"Downloaded {len(df)} rows\", \"SUCCESS\")\n",
        "#         return df\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# def add_technical_indicators(df, logger=None):\n",
        "#     try:\n",
        "#         if logger:\n",
        "#             logger.log(\"Adding technical indicators...\")\n",
        "#         df = df.copy()\n",
        "#         close = df['Close']\n",
        "#         df['SMA_10'] = close.rolling(window=10, min_periods=1).mean()\n",
        "#         df['EMA_10'] = close.ewm(span=10, adjust=False).mean()\n",
        "#         delta = close.diff()\n",
        "#         gain = delta.where(delta > 0, 0.0)\n",
        "#         loss = -delta.where(delta < 0, 0.0)\n",
        "#         avg_gain = gain.rolling(window=14, min_periods=1).mean()\n",
        "#         avg_loss = loss.rolling(window=14, min_periods=1).mean()\n",
        "#         rs = avg_gain / (avg_loss + 1e-8)\n",
        "#         df['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "#         df['Volume_Change'] = df['Volume'].pct_change().fillna(0.0)\n",
        "#         df = df.dropna()\n",
        "#         if logger:\n",
        "#             logger.log(f\"Added indicators, {len(df)} rows remaining\", \"SUCCESS\")\n",
        "#         return df\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Indicator calculation failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# def prepare_sequences(df, seq_len=SEQ_LEN, logger=None):\n",
        "#     try:\n",
        "#         if logger:\n",
        "#             logger.log(\"Preparing sequences...\")\n",
        "#         feature_cols = ['Close', 'SMA_10', 'EMA_10', 'RSI_14', 'Volume_Change']\n",
        "#         missing = [col for col in feature_cols if col not in df.columns]\n",
        "#         if missing:\n",
        "#             raise ValueError(f\"Missing columns for sequence prep: {missing}\")\n",
        "#         arr = df[feature_cols].values.astype(np.float32)\n",
        "#         scaler = MinMaxScaler()\n",
        "#         scaled = scaler.fit_transform(arr)\n",
        "#         X, y = [], []\n",
        "#         for i in range(seq_len, len(scaled)):\n",
        "#             X.append(scaled[i-seq_len:i])\n",
        "#             y.append(scaled[i, 0])  # predict the scaled Close value\n",
        "#         X = np.array(X, dtype=np.float32)\n",
        "#         y = np.array(y, dtype=np.float32)\n",
        "#         if logger:\n",
        "#             logger.log(f\"Created {len(X)} sequences\", \"SUCCESS\")\n",
        "#         n_features = arr.shape[1]\n",
        "#         return X, y, scaler, n_features\n",
        "#     except Exception as e:\n",
        "#         if logger:\n",
        "#             logger.log(f\"Sequence preparation failed: {str(e)}\", \"ERROR\")\n",
        "#         raise\n",
        "\n",
        "# # ---------------- MODEL ARCHITECTURES ----------------\n",
        "# def build_lstm_model(seq_len, n_features):\n",
        "#     model = models.Sequential([\n",
        "#         layers.Input(shape=(seq_len, n_features)),\n",
        "#         layers.LSTM(64, return_sequences=True),\n",
        "#         layers.Dropout(0.2),\n",
        "#         layers.LSTM(32),\n",
        "#         layers.Dense(16, activation='relu'),\n",
        "#         layers.Dense(1)\n",
        "#     ])\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
        "#     return model\n",
        "\n",
        "# def build_bidirectional_lstm_model(seq_len, n_features):\n",
        "#     model = models.Sequential([\n",
        "#         layers.Input(shape=(seq_len, n_features)),\n",
        "#         layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
        "#         layers.Dropout(0.2),\n",
        "#         layers.Bidirectional(layers.LSTM(32)),\n",
        "#         layers.Dense(16, activation='relu'),\n",
        "#         layers.Dense(1)\n",
        "#     ])\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
        "#     return model\n",
        "\n",
        "# # ---------------- MODEL SAVE/LOAD (robust) ----------------\n",
        "# def save_model_tf(model, save_dir, logger):\n",
        "#     try:\n",
        "#         os.makedirs(save_dir, exist_ok=True)\n",
        "#         save_path = os.path.join(save_dir, \"model.keras\")\n",
        "\n",
        "#         # Use .log() instead of calling logger(...)\n",
        "#         logger.log(f\"â„¹ï¸ Saving model to: {save_path}\")\n",
        "\n",
        "#         model.save(save_path)\n",
        "\n",
        "#         logger.log(\"âœ… Model saved successfully!\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         logger.log(f\"âŒ Save failed: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# def load_model_tf(save_dir, logger):\n",
        "#     try:\n",
        "#         model_path = os.path.join(save_dir, \"model.keras\")\n",
        "\n",
        "#         if not os.path.exists(model_path):\n",
        "#             logger.log(\"âŒ No saved model found.\")\n",
        "#             return None\n",
        "\n",
        "#         logger.log(f\"â„¹ï¸ Loading model from: {model_path}\")\n",
        "\n",
        "#         model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "#         logger.log(\"âœ… Model loaded successfully!\")\n",
        "#         return model\n",
        "\n",
        "#     except Exception as e:\n",
        "#         logger.log(f\"âŒ Load failed: {e}\")\n",
        "#         return None\n",
        "\n",
        "\n",
        "# # ---------------- TRAINING THREAD ----------------\n",
        "# def train_models_thread(symbol):\n",
        "#     TRAINING_FLAGS[symbol] = True\n",
        "#     logger = Logger(symbol)\n",
        "#     TRAIN_LOGS[symbol] = TRAIN_LOGS.get(symbol, [])  # ensure exists\n",
        "#     try:\n",
        "#         logger.log(f\"ðŸš€ Starting training for {symbol}\")\n",
        "#         df = download_stock_data(symbol, period='1y', logger=logger)\n",
        "#         df = add_technical_indicators(df, logger=logger)\n",
        "#         X, y, scaler, n_features = prepare_sequences(df, SEQ_LEN, logger=logger)\n",
        "#         if len(X) < 100:\n",
        "#             raise ValueError(f\"Insufficient data: {len(X)} sequences (need 100+ for reliable training)\")\n",
        "#         split_idx = int(len(X) * 0.8)\n",
        "#         X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "#         y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "#         logger.log(f\"Training: {len(X_train)} samples, Testing: {len(X_test)} samples\")\n",
        "#         # LSTM\n",
        "#         logger.log(\"ðŸ—ï¸ Building LSTM model...\")\n",
        "#         lstm_model = build_lstm_model(SEQ_LEN, n_features)\n",
        "#         logger.log(f\"ðŸŽ“ Training LSTM ({EPOCHS} epochs)...\")\n",
        "#         history_lstm = lstm_model.fit(\n",
        "#             X_train, y_train,\n",
        "#             validation_data=(X_test, y_test),\n",
        "#             epochs=EPOCHS,\n",
        "#             batch_size=BATCH_SIZE,\n",
        "#             verbose=0,\n",
        "#             callbacks=[callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        "#         )\n",
        "#         final_loss = history_lstm.history.get('val_loss', [None])[-1]\n",
        "#         logger.log(f\"LSTM trained! Val Loss: {final_loss:.6f}\", \"SUCCESS\")\n",
        "#         lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "#         save_model_tf(lstm_model, lstm_dir, logger)\n",
        "#         # Bidirectional LSTM\n",
        "#         logger.log(\"ðŸ—ï¸ Building Bidirectional LSTM model...\")\n",
        "#         bilstm_model = build_bidirectional_lstm_model(SEQ_LEN, n_features)\n",
        "#         logger.log(f\"ðŸŽ“ Training Bidirectional LSTM ({EPOCHS} epochs)...\")\n",
        "#         history_bilstm = bilstm_model.fit(\n",
        "#             X_train, y_train,\n",
        "#             validation_data=(X_test, y_test),\n",
        "#             epochs=EPOCHS,\n",
        "#             batch_size=BATCH_SIZE,\n",
        "#             verbose=0,\n",
        "#             callbacks=[callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        "#         )\n",
        "#         final_loss2 = history_bilstm.history.get('val_loss', [None])[-1]\n",
        "#         logger.log(f\"Bidirectional LSTM trained! Val Loss: {final_loss2:.6f}\", \"SUCCESS\")\n",
        "#         bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "#         save_model_tf(bilstm_model, bilstm_dir, logger)\n",
        "#         # Save scaler with joblib for reliable inverse_transform\n",
        "#         scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "#         joblib.dump(scaler, scaler_path)\n",
        "#         logger.log(f\"Scaler saved to {scaler_path}\", \"SUCCESS\")\n",
        "#         # Optionally zip the saved model directories for download\n",
        "#         for d in (lstm_dir, bilstm_dir):\n",
        "#             base = d  # full dir path\n",
        "#             zip_path = f\"{base}.zip\"\n",
        "#             if os.path.exists(zip_path):\n",
        "#                 os.remove(zip_path)\n",
        "#             shutil.make_archive(base, 'zip', base)\n",
        "#             logger.log(f\"Created archive {zip_path}\", \"INFO\")\n",
        "#         logger.log(\"ðŸŽ‰ Training completed successfully!\")\n",
        "#     except Exception as e:\n",
        "#         logger.log(f\"Training failed: {str(e)}\", \"ERROR\")\n",
        "#         tb = traceback.format_exc()\n",
        "#         for line in tb.splitlines():\n",
        "#             logger.log(line, \"ERROR\")\n",
        "#     finally:\n",
        "#         TRAINING_FLAGS[symbol] = False\n",
        "\n",
        "# # ---------------- HELPERS ----------------\n",
        "# def is_trained(symbol):\n",
        "#     lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "#     bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "#     scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "#     return os.path.exists(lstm_dir) and os.path.exists(bilstm_dir) and os.path.exists(scaler_path)\n",
        "\n",
        "# def load_models_and_scaler(symbol):\n",
        "#     logger = Logger(symbol)\n",
        "#     lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "#     bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "#     scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "#     lstm_model = load_model_tf(lstm_dir, logger)\n",
        "#     bilstm_model = load_model_tf(bilstm_dir, logger)\n",
        "#     if lstm_model is None or bilstm_model is None:\n",
        "#         raise RuntimeError(\"Failed to load models\")\n",
        "#     if not os.path.exists(scaler_path):\n",
        "#         raise FileNotFoundError(\"Scaler file not found\")\n",
        "#     scaler = joblib.load(scaler_path)\n",
        "#     return lstm_model, bilstm_model, scaler\n",
        "\n",
        "# def ensemble_predict(lstm_model, bilstm_model, X):\n",
        "#     p1 = lstm_model.predict(X, verbose=0).flatten()\n",
        "#     p2 = bilstm_model.predict(X, verbose=0).flatten()\n",
        "#     return (p1 + p2) / 2.0\n",
        "\n",
        "# # ---------------- UI FUNCTIONS ----------------\n",
        "# def start_training(symbol):\n",
        "#     if TRAINING_FLAGS.get(symbol, False):\n",
        "#         return f\"âš ï¸ Training already running for {symbol}\"\n",
        "#     # clear logs for symbol\n",
        "#     TRAIN_LOGS[symbol] = []\n",
        "#     thread = threading.Thread(target=train_models_thread, args=(symbol,), daemon=True)\n",
        "#     thread.start()\n",
        "#     return f\"ðŸš€ Started training for {symbol}. Click 'Refresh Logs' to view progress.\"\n",
        "\n",
        "# def get_training_logs(symbol):\n",
        "#     return logs_to_text(symbol)\n",
        "\n",
        "# def make_prediction(symbol):\n",
        "#     try:\n",
        "#         if not is_trained(symbol):\n",
        "#             return f\"âŒ Models not trained for {symbol}. Train first!\"\n",
        "#         lstm_model, bilstm_model, scaler = load_models_and_scaler(symbol)\n",
        "#         df = download_stock_data(symbol, period='3mo')\n",
        "#         df = add_technical_indicators(df)\n",
        "#         X, y, _, _ = prepare_sequences(df, SEQ_LEN)\n",
        "#         if len(X) == 0:\n",
        "#             return \"âŒ Insufficient data for prediction\"\n",
        "#         last_seq = X[-1:]\n",
        "#         pred_scaled = ensemble_predict(lstm_model, bilstm_model, last_seq)[0]\n",
        "#         # Create dummy vector for inverse transform (same n_features)\n",
        "#         n_features = scaler.scale_.shape[0]\n",
        "#         dummy = np.zeros((1, n_features), dtype=np.float32)\n",
        "#         dummy[0, 0] = pred_scaled\n",
        "#         pred_price = scaler.inverse_transform(dummy)[0, 0]\n",
        "#         current_price = df['Close'].values[-1]\n",
        "#         change_pct = ((pred_price - current_price) / current_price) * 100\n",
        "#         result = (\n",
        "#             f\"ðŸ“Š Prediction for {symbol}\\n\\n\"\n",
        "#             f\"Current Price: ${current_price:.2f}\\n\"\n",
        "#             f\"Predicted Next: ${pred_price:.2f}\\n\"\n",
        "#             f\"Expected Change: {change_pct:+.2f}%\\n\\n\"\n",
        "#             f\"ðŸ¤– Ensemble: LSTM + Bidirectional LSTM\"\n",
        "#         )\n",
        "#         return result\n",
        "#     except Exception as e:\n",
        "#         return f\"âŒ Error during prediction: {str(e)}\"\n",
        "\n",
        "# def get_validation_plot(symbol):\n",
        "#     try:\n",
        "#         if not is_trained(symbol):\n",
        "#             fig = plt.figure(figsize=(10, 4))\n",
        "#             plt.text(0.5, 0.5, f\"Models not trained for {symbol}\\nClick 'Train Models' first\", ha='center', va='center', fontsize=14)\n",
        "#             plt.axis('off')\n",
        "#             return fig\n",
        "#         lstm_model, bilstm_model, scaler = load_models_and_scaler(symbol)\n",
        "#         df = download_stock_data(symbol, period='6mo')\n",
        "#         df = add_technical_indicators(df)\n",
        "#         X, y, _, _ = prepare_sequences(df, SEQ_LEN)\n",
        "#         if len(X) < 2:\n",
        "#             fig = plt.figure(figsize=(10, 4))\n",
        "#             plt.text(0.5, 0.5, \"Insufficient data for validation plot\", ha='center', va='center', fontsize=12)\n",
        "#             plt.axis('off')\n",
        "#             return fig\n",
        "#         split_idx = int(len(X) * 0.8)\n",
        "#         X_test = X[split_idx:]\n",
        "#         y_test = y[split_idx:]\n",
        "#         pred_scaled = ensemble_predict(lstm_model, bilstm_model, X_test)\n",
        "#         # inverse transform\n",
        "#         n_features = scaler.scale_.shape[0]\n",
        "#         dummy_pred = np.zeros((len(pred_scaled), n_features), dtype=np.float32)\n",
        "#         dummy_pred[:, 0] = pred_scaled\n",
        "#         pred_prices = scaler.inverse_transform(dummy_pred)[:, 0]\n",
        "#         dummy_actual = np.zeros((len(y_test), n_features), dtype=np.float32)\n",
        "#         dummy_actual[:, 0] = y_test\n",
        "#         actual_prices = scaler.inverse_transform(dummy_actual)[:, 0]\n",
        "#         fig = plt.figure(figsize=(12, 5))\n",
        "#         plt.plot(actual_prices, label='Actual', linewidth=2)\n",
        "#         plt.plot(pred_prices, label='Predicted', linewidth=2, alpha=0.7)\n",
        "#         plt.title(f'{symbol} - Validation: Actual vs Predicted', fontsize=14, fontweight='bold')\n",
        "#         plt.xlabel('Time Steps')\n",
        "#         plt.ylabel('Price ($)')\n",
        "#         plt.legend()\n",
        "#         plt.grid(True, alpha=0.3)\n",
        "#         plt.tight_layout()\n",
        "#         return fig\n",
        "#     except Exception as e:\n",
        "#         fig = plt.figure(figsize=(10, 4))\n",
        "#         plt.text(0.5, 0.5, f\"Error generating plot:\\n{str(e)}\", ha='center', va='center', fontsize=12)\n",
        "#         plt.axis('off')\n",
        "#         return fig\n",
        "\n",
        "# def download_model_files(symbol):\n",
        "#     if not is_trained(symbol):\n",
        "#         return None, None, None\n",
        "#     lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "#     bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "#     scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "#     lstm_zip = f\"{lstm_dir}.zip\"\n",
        "#     bilstm_zip = f\"{bilstm_dir}.zip\"\n",
        "#     # create zips if missing (safe)\n",
        "#     if not os.path.exists(lstm_zip):\n",
        "#         shutil.make_archive(lstm_dir, 'zip', lstm_dir)\n",
        "#     if not os.path.exists(bilstm_zip):\n",
        "#         shutil.make_archive(bilstm_dir, 'zip', bilstm_dir)\n",
        "#     return lstm_zip, bilstm_zip, scaler_path\n",
        "\n",
        "# # ---------------- GRADIO INTERFACE ----------------\n",
        "# with gr.Blocks(theme=gr.themes.Soft(), title=\"Stock Predictor\") as app:\n",
        "#     gr.Markdown(\"\"\"\n",
        "#     # ðŸ“ˆ Stock Price Predictor\n",
        "#     ### LSTM + Bidirectional LSTM Ensemble Model\n",
        "#     Train models on historical data and predict future stock prices\n",
        "#     \"\"\")\n",
        "#     with gr.Row():\n",
        "#         stock_dropdown = gr.Dropdown(choices=TOP_10_STOCKS, value=\"AAPL\", label=\"ðŸ“Š Select Stock\", interactive=True)\n",
        "#         train_button = gr.Button(\"ðŸš€ Train Models\", variant=\"primary\", size=\"lg\")\n",
        "#     with gr.Row():\n",
        "#         logs_display = gr.Textbox(label=\"ðŸ“‹ Training Logs\", lines=12, max_lines=20, interactive=False)\n",
        "#         refresh_logs_btn = gr.Button(\"ðŸ”„ Refresh Logs\")\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸŽ¯ Make Predictions\")\n",
        "#     with gr.Row():\n",
        "#         predict_button = gr.Button(\"ðŸ”® Predict Next Price\", variant=\"secondary\", size=\"lg\")\n",
        "#         prediction_output = gr.Textbox(label=\"Prediction Result\", lines=7, interactive=False)\n",
        "#     with gr.Row():\n",
        "#         validation_plot = gr.Plot(label=\"ðŸ“Š Validation Plot (Actual vs Predicted)\")\n",
        "#     gr.Markdown(\"---\")\n",
        "#     gr.Markdown(\"## ðŸ’¾ Download Trained Models\")\n",
        "#     with gr.Row():\n",
        "#         lstm_download = gr.File(label=\"LSTM Model (ZIP)\")\n",
        "#         bilstm_download = gr.File(label=\"Bidirectional LSTM Model (ZIP)\")\n",
        "#         scaler_download = gr.File(label=\"Scaler Data\")\n",
        "#     # Events\n",
        "#     train_button.click(fn=start_training, inputs=[stock_dropdown], outputs=[logs_display])\n",
        "#     refresh_logs_btn.click(fn=get_training_logs, inputs=[stock_dropdown], outputs=[logs_display])\n",
        "#     predict_button.click(fn=make_prediction, inputs=[stock_dropdown], outputs=[prediction_output])\n",
        "#     stock_dropdown.change(fn=get_validation_plot, inputs=[stock_dropdown], outputs=[validation_plot])\n",
        "#     stock_dropdown.change(fn=download_model_files, inputs=[stock_dropdown], outputs=[lstm_download, bilstm_download, scaler_download])\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"=\" * 50)\n",
        "#     print(\"ðŸš€ Stock Predictor App Starting...\")\n",
        "#     print(\"=\" * 50)\n",
        "#     app.launch(share=True, debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "VXn_GfRSibOk",
        "outputId": "bf312985-9cde-4e85-e533-2131398c866f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "ðŸš€ Stock Predictor App Starting...\n",
            "==================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2eab905bf587dbb501.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://2eab905bf587dbb501.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, threading, traceback, warnings, shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Non-interactive backend for Colab/Gradio\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "\n",
        "# Suppress noisy warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "TOP_10_STOCKS = [\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\"NFLX\",\"JPM\",\"AMD\"]\n",
        "MODELS_DIR = \"/content/stock_models\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# Quick test defaults (increase for real training)\n",
        "SEQ_LEN = 20\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Shared state\n",
        "TRAIN_LOGS = {}\n",
        "TRAINING_FLAGS = {}\n",
        "\n",
        "# ---------------- LOGGING ----------------\n",
        "class Logger:\n",
        "    def __init__(self, symbol):\n",
        "        self.symbol = symbol\n",
        "        # ensure logs list exists\n",
        "        TRAIN_LOGS.setdefault(symbol, [])\n",
        "        self.logs = TRAIN_LOGS[symbol]\n",
        "\n",
        "    def log(self, msg, level=\"INFO\"):\n",
        "        timestamp = time.strftime(\"%H:%M:%S\")\n",
        "        emoji = {\"INFO\": \"â„¹ï¸\", \"SUCCESS\": \"âœ…\", \"ERROR\": \"âŒ\", \"WARNING\": \"âš ï¸\"}.get(level, \"ðŸ“\")\n",
        "        line = f\"[{timestamp}] {emoji} {msg}\"\n",
        "        self.logs.append(line)\n",
        "        TRAIN_LOGS[self.symbol] = self.logs\n",
        "        print(line)\n",
        "        return line\n",
        "\n",
        "def logs_to_text(symbol):\n",
        "    logs = TRAIN_LOGS.get(symbol, [])\n",
        "    if not logs:\n",
        "        return \"No logs yet. Click 'Train Models' to start.\"\n",
        "    status = \"ðŸ”„ Training in progress...\\n\\n\" if TRAINING_FLAGS.get(symbol, False) else \"âœ… Training completed (or not started)\\n\\n\"\n",
        "    return status + \"\\n\".join(logs)\n",
        "\n",
        "# ---------------- DATA UTILITIES ----------------\n",
        "def download_stock_data(symbol, period='1y', logger=None):\n",
        "    try:\n",
        "        if logger:\n",
        "            logger.log(f\"Downloading {symbol} data ({period})...\")\n",
        "        df = yf.download(symbol, period=period, interval='1d', progress=False, auto_adjust=True, threads=False)\n",
        "        if df is None or df.empty:\n",
        "            raise ValueError(f\"No data returned for {symbol} (period={period})\")\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = df.columns.get_level_values(0)\n",
        "        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "        missing = [c for c in required_cols if c not in df.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing required columns from Yahoo: {missing}\")\n",
        "        df = df[required_cols].copy()\n",
        "        df = df.dropna()\n",
        "        if logger:\n",
        "            logger.log(f\"Downloaded {len(df)} rows\", \"SUCCESS\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.log(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "        raise\n",
        "\n",
        "def add_technical_indicators(df, logger=None):\n",
        "    try:\n",
        "        if logger:\n",
        "            logger.log(\"Adding technical indicators...\")\n",
        "        df = df.copy()\n",
        "        close = df['Close']\n",
        "        df['SMA_10'] = close.rolling(window=10, min_periods=1).mean()\n",
        "        df['EMA_10'] = close.ewm(span=10, adjust=False).mean()\n",
        "        delta = close.diff()\n",
        "        gain = delta.where(delta > 0, 0.0)\n",
        "        loss = -delta.where(delta < 0, 0.0)\n",
        "        avg_gain = gain.rolling(window=14, min_periods=1).mean()\n",
        "        avg_loss = loss.rolling(window=14, min_periods=1).mean()\n",
        "        rs = avg_gain / (avg_loss + 1e-8)\n",
        "        df['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "        df['Volume_Change'] = df['Volume'].pct_change().fillna(0.0)\n",
        "        df = df.dropna()\n",
        "        if logger:\n",
        "            logger.log(f\"Added indicators, {len(df)} rows remaining\", \"SUCCESS\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.log(f\"Indicator calculation failed: {str(e)}\", \"ERROR\")\n",
        "        raise\n",
        "\n",
        "def prepare_sequences(df, seq_len=SEQ_LEN, logger=None):\n",
        "    try:\n",
        "        if logger:\n",
        "            logger.log(\"Preparing sequences...\")\n",
        "        feature_cols = ['Close', 'SMA_10', 'EMA_10', 'RSI_14', 'Volume_Change']\n",
        "        missing = [col for col in feature_cols if col not in df.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing columns for sequence prep: {missing}\")\n",
        "        arr = df[feature_cols].values.astype(np.float32)\n",
        "        scaler = MinMaxScaler()\n",
        "        scaled = scaler.fit_transform(arr)\n",
        "        X, y = [], []\n",
        "        for i in range(seq_len, len(scaled)):\n",
        "            X.append(scaled[i-seq_len:i])\n",
        "            y.append(scaled[i, 0])\n",
        "        X = np.array(X, dtype=np.float32)\n",
        "        y = np.array(y, dtype=np.float32)\n",
        "        if logger:\n",
        "            logger.log(f\"Created {len(X)} sequences\", \"SUCCESS\")\n",
        "        n_features = arr.shape[1]\n",
        "        return X, y, scaler, n_features\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.log(f\"Sequence preparation failed: {str(e)}\", \"ERROR\")\n",
        "        raise\n",
        "\n",
        "# ---------------- MODELS ----------------\n",
        "def build_lstm_model(seq_len, n_features):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(seq_len, n_features)),\n",
        "        layers.LSTM(128, return_sequences=True),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.LSTM(64),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "def build_bidirectional_lstm_model(seq_len, n_features):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(seq_len, n_features)),\n",
        "        layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Bidirectional(layers.LSTM(64)),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# ---------------- SAVE / LOAD (Keras 3 friendly) ----------------\n",
        "def save_model_tf(model, save_dir, logger):\n",
        "    try:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        save_path = os.path.join(save_dir, \"model.keras\")\n",
        "        logger.log(f\"â„¹ï¸ Saving model to: {save_path}\")\n",
        "        # Keras 3 will use .keras extension\n",
        "        model.save(save_path)\n",
        "        logger.log(\"âœ… Model saved successfully!\")\n",
        "    except Exception as e:\n",
        "        logger.log(f\"âŒ Save failed: {e}\", \"ERROR\")\n",
        "        raise\n",
        "\n",
        "def load_model_tf(save_dir, logger):\n",
        "    try:\n",
        "        model_path = os.path.join(save_dir, \"model.keras\")\n",
        "        if not os.path.exists(model_path):\n",
        "            logger.log(\"âŒ No saved model found.\", \"ERROR\")\n",
        "            return None\n",
        "        logger.log(f\"â„¹ï¸ Loading model from: {model_path}\")\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "        logger.log(\"âœ… Model loaded successfully!\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.log(f\"âŒ Load failed: {e}\", \"ERROR\")\n",
        "        return None\n",
        "\n",
        "# ---------------- TRAINING THREAD ----------------\n",
        "def train_models_thread(symbol):\n",
        "    TRAINING_FLAGS[symbol] = True\n",
        "    logger = Logger(symbol)\n",
        "    TRAIN_LOGS.setdefault(symbol, [])\n",
        "    try:\n",
        "        logger.log(f\"ðŸš€ Starting training for {symbol}\")\n",
        "        df = download_stock_data(symbol, period='1y', logger=logger)\n",
        "        df = add_technical_indicators(df, logger=logger)\n",
        "        X, y, scaler, n_features = prepare_sequences(df, SEQ_LEN, logger=logger)\n",
        "        if len(X) < 100:\n",
        "            raise ValueError(f\"Insufficient data: {len(X)} sequences (need 100+ for reliable training)\")\n",
        "        split_idx = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "        logger.log(f\"Training: {len(X_train)} samples, Testing: {len(X_test)} samples\")\n",
        "        # Train LSTM\n",
        "        logger.log(\"ðŸ—ï¸ Building LSTM model...\")\n",
        "        lstm_model = build_lstm_model(SEQ_LEN, n_features)\n",
        "        logger.log(f\"ðŸŽ“ Training LSTM ({EPOCHS} epochs)...\")\n",
        "        history_lstm = lstm_model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            verbose=0,\n",
        "            callbacks=[callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        "        )\n",
        "        final_loss = history_lstm.history.get('val_loss', [None])[-1]\n",
        "        logger.log(f\"LSTM trained! Val Loss: {final_loss:.6f}\", \"SUCCESS\")\n",
        "        lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "        save_model_tf(lstm_model, lstm_dir, logger)\n",
        "        # Train Bidirectional LSTM\n",
        "        logger.log(\"ðŸ—ï¸ Building Bidirectional LSTM model...\")\n",
        "        bilstm_model = build_bidirectional_lstm_model(SEQ_LEN, n_features)\n",
        "        logger.log(f\"ðŸŽ“ Training Bidirectional LSTM ({EPOCHS} epochs)...\")\n",
        "        history_bilstm = bilstm_model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            verbose=0,\n",
        "            callbacks=[callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        "        )\n",
        "        final_loss2 = history_bilstm.history.get('val_loss', [None])[-1]\n",
        "        logger.log(f\"Bidirectional LSTM trained! Val Loss: {final_loss2:.6f}\", \"SUCCESS\")\n",
        "        bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "        save_model_tf(bilstm_model, bilstm_dir, logger)\n",
        "        # Save scaler\n",
        "        scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "        joblib.dump(scaler, scaler_path)\n",
        "        logger.log(f\"Scaler saved to {scaler_path}\", \"SUCCESS\")\n",
        "        # Zip saved models for download\n",
        "        for d in (lstm_dir, bilstm_dir):\n",
        "            base = d\n",
        "            zip_path = f\"{base}.zip\"\n",
        "            if os.path.exists(zip_path):\n",
        "                os.remove(zip_path)\n",
        "            shutil.make_archive(base, 'zip', base)\n",
        "            logger.log(f\"Created archive {zip_path}\", \"INFO\")\n",
        "        logger.log(\"ðŸŽ‰ Training completed successfully!\", \"SUCCESS\")\n",
        "    except Exception as e:\n",
        "        logger.log(f\"Training failed: {str(e)}\", \"ERROR\")\n",
        "        tb = traceback.format_exc()\n",
        "        for line in tb.splitlines():\n",
        "            logger.log(line, \"ERROR\")\n",
        "    finally:\n",
        "        TRAINING_FLAGS[symbol] = False\n",
        "\n",
        "# ---------------- HELPERS ----------------\n",
        "def is_trained(symbol):\n",
        "    lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "    bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "    scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "    return os.path.exists(lstm_dir) and os.path.exists(bilstm_dir) and os.path.exists(scaler_path)\n",
        "\n",
        "def load_models_and_scaler(symbol):\n",
        "    logger = Logger(symbol)\n",
        "    lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "    bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "    scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "    lstm_model = load_model_tf(lstm_dir, logger)\n",
        "    bilstm_model = load_model_tf(bilstm_dir, logger)\n",
        "    if lstm_model is None or bilstm_model is None:\n",
        "        raise RuntimeError(\"Failed to load models\")\n",
        "    if not os.path.exists(scaler_path):\n",
        "        raise FileNotFoundError(\"Scaler file not found\")\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    return lstm_model, bilstm_model, scaler\n",
        "\n",
        "def ensemble_predict(lstm_model, bilstm_model, X):\n",
        "    p1 = lstm_model.predict(X, verbose=0).flatten()\n",
        "    p2 = bilstm_model.predict(X, verbose=0).flatten()\n",
        "    return (p1 + p2) / 2.0\n",
        "\n",
        "# ---------------- UI FUNCTIONS ----------------\n",
        "def start_training(symbol):\n",
        "    if TRAINING_FLAGS.get(symbol, False):\n",
        "        return f\"âš ï¸ Training already running for {symbol}\"\n",
        "    TRAIN_LOGS[symbol] = []\n",
        "    thread = threading.Thread(target=train_models_thread, args=(symbol,), daemon=True)\n",
        "    thread.start()\n",
        "    return f\"ðŸš€ Started training for {symbol}. Click 'Refresh Logs' to view progress.\"\n",
        "\n",
        "def get_training_logs(symbol):\n",
        "    return logs_to_text(symbol)\n",
        "\n",
        "def make_prediction(symbol):\n",
        "    try:\n",
        "        if not is_trained(symbol):\n",
        "            return f\"âŒ Models not trained for {symbol}. Train first!\"\n",
        "        lstm_model, bilstm_model, scaler = load_models_and_scaler(symbol)\n",
        "        df = download_stock_data(symbol, period='3mo')\n",
        "        df = add_technical_indicators(df)\n",
        "        X, y, _, _ = prepare_sequences(df, SEQ_LEN)\n",
        "        if len(X) == 0:\n",
        "            return \"âŒ Insufficient data for prediction\"\n",
        "        last_seq = X[-1:]\n",
        "        pred_scaled = ensemble_predict(lstm_model, bilstm_model, last_seq)[0]\n",
        "        n_features = scaler.scale_.shape[0]\n",
        "        dummy = np.zeros((1, n_features), dtype=np.float32)\n",
        "        dummy[0, 0] = pred_scaled\n",
        "        pred_price = scaler.inverse_transform(dummy)[0, 0]\n",
        "        current_price = df['Close'].values[-1]\n",
        "        change_pct = ((pred_price - current_price) / current_price) * 100\n",
        "        result = (\n",
        "            f\"ðŸ“Š Prediction for {symbol}\\n\\n\"\n",
        "            f\"Current Price: ${current_price:.2f}\\n\"\n",
        "            f\"Predicted Next: ${pred_price:.2f}\\n\"\n",
        "            f\"Expected Change: {change_pct:+.2f}%\\n\\n\"\n",
        "            f\"ðŸ¤– Ensemble: LSTM + Bidirectional LSTM\"\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error during prediction: {str(e)}\"\n",
        "\n",
        "def get_validation_plot(symbol):\n",
        "    try:\n",
        "        plt.close('all')  # clear previous figures\n",
        "        if not is_trained(symbol):\n",
        "            fig, ax = plt.subplots(figsize=(10, 4))\n",
        "            ax.text(0.5, 0.5, f\"Models not trained for {symbol}\\nClick 'Train Models' first\", ha='center', va='center', fontsize=14)\n",
        "            ax.axis('off')\n",
        "            return fig\n",
        "        lstm_model, bilstm_model, scaler = load_models_and_scaler(symbol)\n",
        "        df = download_stock_data(symbol, period='6mo')\n",
        "        df = add_technical_indicators(df)\n",
        "        X, y, _, _ = prepare_sequences(df, SEQ_LEN)\n",
        "        if len(X) < 2:\n",
        "            fig, ax = plt.subplots(figsize=(10, 4))\n",
        "            ax.text(0.5, 0.5, \"Insufficient data for validation plot\", ha='center', va='center', fontsize=12)\n",
        "            ax.axis('off')\n",
        "            return fig\n",
        "        split_idx = int(len(X) * 0.8)\n",
        "        X_test = X[split_idx:]\n",
        "        y_test = y[split_idx:]\n",
        "        pred_scaled = ensemble_predict(lstm_model, bilstm_model, X_test)\n",
        "        n_features = scaler.scale_.shape[0]\n",
        "        dummy_pred = np.zeros((len(pred_scaled), n_features), dtype=np.float32)\n",
        "        dummy_pred[:, 0] = pred_scaled\n",
        "        pred_prices = scaler.inverse_transform(dummy_pred)[:, 0]\n",
        "        dummy_actual = np.zeros((len(y_test), n_features), dtype=np.float32)\n",
        "        dummy_actual[:, 0] = y_test\n",
        "        actual_prices = scaler.inverse_transform(dummy_actual)[:, 0]\n",
        "        fig, ax = plt.subplots(figsize=(12, 5))\n",
        "        ax.plot(actual_prices, label='Actual', linewidth=2)\n",
        "        ax.plot(pred_prices, label='Predicted', linewidth=2, alpha=0.7)\n",
        "        ax.set_title(f'{symbol} - Validation: Actual vs Predicted', fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel('Time Steps')\n",
        "        ax.set_ylabel('Price ($)')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        fig, ax = plt.subplots(figsize=(10, 4))\n",
        "        ax.text(0.5, 0.5, f\"Error generating plot:\\n{str(e)}\", ha='center', va='center', fontsize=12)\n",
        "        ax.axis('off')\n",
        "        return fig\n",
        "\n",
        "def get_head_of_data(symbol):\n",
        "    \"\"\"Return df.head(10) after indicators (3 months of data) as a pandas DataFrame\"\"\"\n",
        "    try:\n",
        "        df = download_stock_data(symbol, period='3mo')\n",
        "        df = add_technical_indicators(df)\n",
        "        # ensure we return a DataFrame\n",
        "        return df.head(10)\n",
        "    except Exception:\n",
        "        # return empty DataFrame on failure\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def download_model_files(symbol):\n",
        "    if not is_trained(symbol):\n",
        "        return None, None, None\n",
        "    lstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_lstm_saved_model\")\n",
        "    bilstm_dir = os.path.join(MODELS_DIR, f\"{symbol}_bilstm_saved_model\")\n",
        "    scaler_path = os.path.join(MODELS_DIR, f\"{symbol}_scaler.joblib\")\n",
        "    lstm_zip = f\"{lstm_dir}.zip\"\n",
        "    bilstm_zip = f\"{bilstm_dir}.zip\"\n",
        "    if not os.path.exists(lstm_zip):\n",
        "        shutil.make_archive(lstm_dir, 'zip', lstm_dir)\n",
        "    if not os.path.exists(bilstm_zip):\n",
        "        shutil.make_archive(bilstm_dir, 'zip', bilstm_dir)\n",
        "    return lstm_zip, bilstm_zip, scaler_path\n",
        "\n",
        "# ---------------- GRADIO UI ----------------\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Stock Predictor\") as app:\n",
        "    def get_dataset_preview(symbol):\n",
        "        try:\n",
        "            df = download_stock_data(symbol, period='6mo')\n",
        "            df = add_technical_indicators(df)\n",
        "            return df.head(10)\n",
        "        except Exception as e:\n",
        "            return pd.DataFrame({\"Error\": [str(e)]})\n",
        "\n",
        "    with gr.Row():\n",
        "        stock_dropdown = gr.Dropdown(choices=TOP_10_STOCKS, value=\"AAPL\", label=\"ðŸ“Š Select Stock\", interactive=True)\n",
        "        train_button = gr.Button(\"ðŸš€ Train Models\", variant=\"primary\", size=\"lg\")\n",
        "    with gr.Row():\n",
        "        logs_display = gr.Textbox(label=\"ðŸ“‹ Training Logs\", lines=12, max_lines=20, interactive=False)\n",
        "        refresh_logs_btn = gr.Button(\"ðŸ”„ Refresh Logs\")\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"## ðŸŽ¯ Make Predictions\")\n",
        "    with gr.Row():\n",
        "        predict_button = gr.Button(\"ðŸ”® Predict Next Price\", variant=\"secondary\", size=\"lg\")\n",
        "        prediction_output = gr.Textbox(label=\"Prediction Result\", lines=7, interactive=False)\n",
        "    with gr.Row():\n",
        "        validation_plot = gr.Plot(label=\"ðŸ“Š Validation Plot (Actual vs Predicted)\")\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"## ðŸ—’ï¸ Dataset Preview (head(10))\")\n",
        "    with gr.Row():\n",
        "      df_preview = gr.Dataframe(label=\"Dataset Preview (first 10 rows)\", interactive=False)\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"## ðŸ’¾ Download Trained Models\")\n",
        "    with gr.Row():\n",
        "        lstm_download = gr.File(label=\"LSTM Model (ZIP)\")\n",
        "        bilstm_download = gr.File(label=\"Bidirectional LSTM Model (ZIP)\")\n",
        "        scaler_download = gr.File(label=\"Scaler Data\")\n",
        "    # Events\n",
        "    train_button.click(fn=start_training, inputs=[stock_dropdown], outputs=[logs_display])\n",
        "    refresh_logs_btn.click(fn=get_training_logs, inputs=[stock_dropdown], outputs=[logs_display])\n",
        "    predict_button.click(fn=make_prediction, inputs=[stock_dropdown], outputs=[prediction_output])\n",
        "    # ensure plot updates when clicking Predict\n",
        "    predict_button.click(fn=get_validation_plot, inputs=[stock_dropdown], outputs=[validation_plot])\n",
        "    # dataset head updates on Predict and when changing dropdown\n",
        "    predict_button.click(fn=get_head_of_data, inputs=[stock_dropdown], outputs=[df_preview])\n",
        "    stock_dropdown.change(fn=get_head_of_data, inputs=[stock_dropdown], outputs=[df_preview])\n",
        "    # update downloads when stock selection changes\n",
        "    stock_dropdown.change(fn=download_model_files, inputs=[stock_dropdown], outputs=[lstm_download, bilstm_download, scaler_download])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 50)\n",
        "    print(\"ðŸš€ Stock Predictor App Starting...\")\n",
        "    print(\"=\" * 50)\n",
        "    app.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "7oTtCv_2iccA",
        "outputId": "1d94ed48-3b24-4b57-e932-fe582d4bfc2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "ðŸš€ Stock Predictor App Starting...\n",
            "==================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9fee59a26c8cac8792.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9fee59a26c8cac8792.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaLS_vzVpAOz"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}